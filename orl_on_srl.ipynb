{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":8091059,"sourceType":"datasetVersion","datasetId":4776887}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/houmannorasteh/mpqa-on-srl?scriptVersionId=171511269\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:06.646681Z","iopub.execute_input":"2024-04-11T15:23:06.647552Z","iopub.status.idle":"2024-04-11T15:23:30.33226Z","shell.execute_reply.started":"2024-04-11T15:23:06.647513Z","shell.execute_reply":"2024-04-11T15:23:30.33115Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### importing libraries ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nfrom itertools import zip_longest","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:30.334341Z","iopub.execute_input":"2024-04-11T15:23:30.334674Z","iopub.status.idle":"2024-04-11T15:23:33.294963Z","shell.execute_reply.started":"2024-04-11T15:23:30.334643Z","shell.execute_reply":"2024-04-11T15:23:33.294224Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### defining general variables","metadata":{}},{"cell_type":"code","source":"#defining global valriables throughout the whole notebook\nEPOCH = 10\nBATCH_SIZE = 16\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:33.295975Z","iopub.execute_input":"2024-04-11T15:23:33.296366Z","iopub.status.idle":"2024-04-11T15:23:33.300864Z","shell.execute_reply.started":"2024-04-11T15:23:33.29634Z","shell.execute_reply":"2024-04-11T15:23:33.299977Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:33.302047Z","iopub.execute_input":"2024-04-11T15:23:33.302404Z","iopub.status.idle":"2024-04-11T15:23:35.337703Z","shell.execute_reply.started":"2024-04-11T15:23:33.30236Z","shell.execute_reply":"2024-04-11T15:23:35.336822Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### functions created for reading(get_data) and organize the files (organize_data)","metadata":{}},{"cell_type":"code","source":"# a funciton to read data off of a database link is here to help getting and organizing data into dataframes\ndef get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe\n\n# this function is to make a list of the said attribute for later iterations\ndef list_of(attributes, requested_atr):\n    requested_list = []\n    for sublist in attributes:\n        if sublist[-1] == requested_atr:\n            requested_list.append(sublist)\n    return requested_list\n\n# this function was made to find target(s)/agent(s) of a dse according to list of attributes\ndef organize_data(attributes, sentence):\n    AGENT, DSE, TARGET = '', '', ''\n    target_flag, agent_flag = False, False\n    for sublist in attributes:\n        if sublist[-1] == 'DSE':\n            dse_start = int(sublist[0])\n            dse_end = int(sublist[1] + 1)\n            DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n            \n            \n            # looking for the targets and agents of this dse that we have found\n            target_flag = False\n            for sub_sublist in list_of(attributes, 'TARGET'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    target_start = int(sub_sublist[2])\n                    target_end = int(sub_sublist[3] + 1)\n                    TARGET += ' '.join(sentence[target_start:target_end]) + '|'\n                    target_flag = True\n            if not target_flag:\n                TARGET += ' |'\n            \n            agent_flag = False\n            for sub_sublist in list_of(attributes, 'AGENT'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    agent_start = int(sub_sublist[2])\n                    agent_end = int(sub_sublist[3] + 1)\n                    AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n                    agent_flag = True\n            if not agent_flag:\n                AGENT += ' |'\n    return AGENT, DSE, TARGET","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### a function to call for different links of folders with exact process to extract and organize data","metadata":{}},{"cell_type":"code","source":"def get_files_of_folder(folder_number):\n    folder_number = int()\n    folder = f\"/kaggle/input/ds-json-format/json_format_dataset/{folder_number}\"\n    dev_df = get_data(f\"{folder}/aaai19srl.dev{folder_number}.conll.json\")\n    df = get_data(f\"{folder}/aaai19srl.train{folder_number}.conll.json\")\n    test_df = get_data(f\"{folder}/aaai19srl.test{folder_number}.conll.json\")\n    return df, dev_df, test_df\ndf = get_files_of_folder(4)[0]\ndev_df = get_files_of_folder(4)[1]\ntest_df = get_files_of_folder(4)[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### getting training/validation/test data into data frames and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"# df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\n\nfor i in range(len(df)):\n    agent, dse, target = organize_data(df['orl'][i], df['sep_sent'][i])\n    df.loc[i, 'agent'] = agent\n    df.loc[i, 'dse'] = dse\n    df.loc[i, 'target'] = target\n\ndf.drop(columns='sep_sent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dev_df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.dev0.conll.json\")\n\nfor i in range(len(dev_df)):\n    agent, dse, target = organize_data(dev_df['orl'][i], dev_df['sep_sent'][i])\n    dev_df.loc[i, 'agent'] = agent\n    dev_df.loc[i, 'dse'] = dse\n    dev_df.loc[i, 'target'] = target\n\ndev_df.drop(columns='sep_sent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.test0.conll.json\")\n\nfor i in range(len(test_df)):\n    agent, dse, target = organize_data(test_df['orl'][i], test_df['sep_sent'][i])\n    test_df.loc[i, 'agent'] = agent\n    test_df.loc[i, 'dse'] = dse\n    test_df.loc[i, 'target'] = target\n\ntest_df.drop(columns='sep_sent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting evaluation data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"def pipeDivider(pipedString):\n    listOfItems = []\n    listOfItems = pipedString.split('|')[:-1]\n    return listOfItems","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function which will write prompt for the model according to the sentence and the items in it\ndef create_prompt(input_df):\n    output_df = pd.DataFrame(columns=['target_prompt', 'agent_prompt', 'target', 'agent'])\n    for i in range(len(input_df)):\n        dse_list, target_list, agent_list = [], [], []\n        dse_list = pipeDivider(str(input_df.iloc[i]['dse']))\n        target_list = pipeDivider(str(input_df.iloc[i]['target']))\n        agent_list = pipeDivider(str(input_df.iloc[i]['agent']))\n        for j in range(len(dse_list)):\n            last_row = int(len(output_df))+1\n            output_df.loc[last_row, 'target_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find target for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'agent_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find agent for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'target'] = target_list[j]\n            output_df.loc[last_row, 'agent'] = agent_list[j]\n    return output_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = create_prompt(df)\ntrain_df.head(-10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Change the sentence and dse into a prompt according to information in that row \n#### change will be applied on all three data frames {train, test, validation}","metadata":{}},{"cell_type":"code","source":"dev_df = create_prompt(dev_df)\ntrain_df = create_prompt(df)\ntest_df = create_prompt(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ndev_df = dev_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        agent_prompt = self.data['agent_prompt'][idx]\n        target_prompt = self.data['target_prompt'][idx]\n        agent = self.data['agent'][idx]\n        target = self.data['target'][idx]\n        # tokenizing agent prompt\n        agent_prompt_encoding = self.tokenizer(agent_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing target prompt\n        target_prompt_encoding = self.tokenizer(target_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        # tokenizing target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent prompt\n            'agent_input_id': agent_prompt_encoding['input_ids'].squeeze(),\n            'agent_attention_mask': agent_prompt_encoding['attention_mask'].squeeze(),\n            # target prompt\n            'target_input_id': target_prompt_encoding['input_ids'].squeeze(),\n            'target_attention_mask': target_prompt_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:39.386402Z","iopub.execute_input":"2024-04-11T15:23:39.38694Z","iopub.status.idle":"2024-04-11T15:23:39.398633Z","shell.execute_reply.started":"2024-04-11T15:23:39.386886Z","shell.execute_reply":"2024-04-11T15:23:39.397632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create a data loader for TRAIN dataframe \ntrain_dataset = CustomDataset(train_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for EVALUATION dataframe\nval_dataset = CustomDataset(dev_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Create a data loader for TEST dataframe\ntest_dataset = CustomDataset(test_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntest_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:25:15.830661Z","iopub.execute_input":"2024-04-11T15:25:15.831431Z","iopub.status.idle":"2024-04-11T15:25:15.837413Z","shell.execute_reply.started":"2024-04-11T15:25:15.831389Z","shell.execute_reply":"2024-04-11T15:25:15.836382Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def f1_calculator(pred_list, actual_list):\n    cleaned_pred, cleaned_actual = [], []\n    matched = 0\n    for i in range(len(pred_list)):\n        for j in range(len(actual_list)):\n            if actual_list[j] in pred_list:\n                matched += 1\n        cleaned_pred.extend(pred_list)\n        cleaned_actual.extend(actual_list)\n    \n    prediction_len = len(cleaned_pred)\n    actual_len = len(cleaned_actual)\n    print(f'matched: {matched}, prediction_len:{prediction_len}, actual_len:{actual_len} \\n')\n    try:\n        precision = (matched / prediction_len)\n        recall = (matched / actual_len)\n        f1 = (2 * (precision * recall)) / (precision + recall)\n    except:\n        f1 = 0\n    return f1","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:44.028217Z","iopub.execute_input":"2024-04-11T15:23:44.028598Z","iopub.status.idle":"2024-04-11T15:23:44.035831Z","shell.execute_reply.started":"2024-04-11T15:23:44.028565Z","shell.execute_reply":"2024-04-11T15:23:44.03486Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, prompt_type):\n    if prompt_type == 'target':\n        id_type = 'target_input_id'\n        attention_type = 'target_attention_mask'\n        output_type = 'target_id'\n    elif prompt_type == 'agent':\n        id_type = 'agent_input_id'\n        attention_type = 'agent_attention_mask'\n        output_type = 'agent_id'\n    \n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        true_counted, prediction_counted, actual_counted = 0,0,0\n        matched, prediction_len, actual_len = 0,0,0\n        actual_list, prediction_list, f1 = [], [], []\n        for batch_idx, batch in enumerate(dataloader):\n            # Move data to the specified device\n            # batch = {key: value.to('cuda') for key, value in batch.items()}\n\n            # Forward pass\n            ids = batch[id_type]\n            mask = batch[attention_type]\n            output_id = batch[output_type]\n            \n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output_id]\n            \n            generated_output = generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=64, \n              )\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_output]\n            \n            actual_list.extend(actuals)\n            prediction_list.extend(preds)\n    return f1_calculator(prediction_list, actual_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:23:47.931151Z","iopub.execute_input":"2024-04-11T15:23:47.931549Z","iopub.status.idle":"2024-04-11T15:23:47.942074Z","shell.execute_reply.started":"2024-04-11T15:23:47.931512Z","shell.execute_reply":"2024-04-11T15:23:47.941093Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_data(data_loader, v_data_loader):\n    model.train()\n    for epoch in range(EPOCH):\n        losses = []\n        for batch in data_loader:\n\n            agent_input = batch['agent_input_id']\n            agent_attention_mask = batch['agent_attention_mask']\n\n            target_input = batch['target_input_id']\n            target_attention_mask = batch['target_attention_mask']\n\n            agent_id = batch['agent_id']\n            agent_mask = batch['agent_mask']\n\n            target_id = batch['target_id']\n            target_mask = batch['target_mask']\n\n            optimizer.zero_grad()\n\n            agent_output = model(agent_input, attention_mask=agent_attention_mask, labels=agent_id)\n            target_output = model(target_input, attention_mask=target_attention_mask, labels=target_id)\n\n            agent_loss = agent_output.loss\n            target_loss = target_output.loss\n            losses.append(agent_loss.item())\n            losses.append(target_loss.item())\n\n            agent_loss.backward()\n            target_loss.backward()\n            optimizer.step()\n\n        f1_4_target = evaluate_model(model, v_data_loader, 'target')\n        f1_4_agent = evaluate_model(model, v_data_loader, 'agent')\n        print(f'loss: {np.mean(losses)}, f1 for target:{f1_4_target}, f1 for agent:{f1_4_agent} \\n end of epoch{epoch}. \\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-11T16:21:39.269282Z","iopub.execute_input":"2024-04-11T16:21:39.270282Z","iopub.status.idle":"2024-04-11T16:21:39.28016Z","shell.execute_reply.started":"2024-04-11T16:21:39.270243Z","shell.execute_reply":"2024-04-11T16:21:39.279085Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# for folder 1:\ntrain_data(train_data_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we can either use the model we trained above, or we can use the link to the same model.","metadata":{}},{"cell_type":"code","source":"# # defining a new model to fit the state dictionary of the previously trained model to it.\n# new_model = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')\n\n# state_dict = torch.load(\"/kaggle/input/t5-small_trained_mpqa/pytorch/t5-small_mpqa_v1/1/t5_orl_model.pt\")\n# new_model.load_state_dict(state_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we are gonna load the test dataset into evaluation method to calculate score","metadata":{}},{"cell_type":"markdown","source":"### Applying 10 percent of SRL to the trained data to see how good or bad does it perform","metadata":{}},{"cell_type":"markdown","source":"##### importing and cleaning data for training","metadata":{}},{"cell_type":"code","source":"srl = pd.read_csv('/kaggle/input/10-of-srl/10_percent.csv')\nagents, targets, verbs, sentences = [], [], [], []\nfor i in range(len(srl)):\n    line = srl.iloc[i]\n    temp = line['arguments'].split('|')\n    agents.append(temp[0])\n    targets.append(temp[1])\n    sentences.append(line['sentence'])\n    verbs.append(line['predicate'])\n\nsrl_df = pd.DataFrame({'sentences': sentences, 'verbs': verbs, 'agents': agents, 'targets': targets})\nsrl_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:24:02.16716Z","iopub.execute_input":"2024-04-11T15:24:02.167799Z","iopub.status.idle":"2024-04-11T15:24:02.673273Z","shell.execute_reply.started":"2024-04-11T15:24:02.16776Z","shell.execute_reply":"2024-04-11T15:24:02.672293Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                           sentences       verbs  \\\n0  Pierre Vinken, 61 years old, will join the boa...        join   \n1  Mr. Vinken is chairman of Elsevier N.V., the D...  publishing   \n2  Rudolph Agnew, 55 years old and former chairma...       named   \n3  A form of asbestos once used * * to make Kent ...        used   \n4  A form of asbestos once used * * to make Kent ...        make   \n\n                         agents  \\\n0  Pierre Vinken, 61 years old,   \n1                         group   \n2                                 \n3                                 \n4                             *   \n\n                                             targets  \n0                                          the board  \n1                                                     \n2  Rudolph Agnew, 55 years old and former chairma...  \n3                               A form of asbestos *  \n4                             Kent cigarette filters  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentences</th>\n      <th>verbs</th>\n      <th>agents</th>\n      <th>targets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Pierre Vinken, 61 years old, will join the boa...</td>\n      <td>join</td>\n      <td>Pierre Vinken, 61 years old,</td>\n      <td>the board</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mr. Vinken is chairman of Elsevier N.V., the D...</td>\n      <td>publishing</td>\n      <td>group</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rudolph Agnew, 55 years old and former chairma...</td>\n      <td>named</td>\n      <td></td>\n      <td>Rudolph Agnew, 55 years old and former chairma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A form of asbestos once used * * to make Kent ...</td>\n      <td>used</td>\n      <td></td>\n      <td>A form of asbestos *</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A form of asbestos once used * * to make Kent ...</td>\n      <td>make</td>\n      <td>*</td>\n      <td>Kent cigarette filters</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"##### in this format which data is ready to be used, we make appropriate changes (like adding prompt) to feed it to the data loader for later usage.","metadata":{}},{"cell_type":"code","source":"agent_prompts, agents, target_prompts, targets = [], [], [], []\nfor i in range(len(srl_df)):\n    line = srl_df.iloc[i]\n    agent_prompts.append(f\" sentence is: {line['sentences']} find agent for this verb: {line['verbs']}\")\n    agents.append(line['agents'])\n    target_prompts.append(f\" sentence is: {line['sentences']} find target for this verb: {line['verbs']}\")\n    targets.append(line['targets'])\nsrl_df = []\nsrl_df = pd.DataFrame({'agent_prompt': agent_prompts, 'agent': agents, 'target_prompt': target_prompts, 'target': targets})\nsrl_df","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:24:08.930516Z","iopub.execute_input":"2024-04-11T15:24:08.931397Z","iopub.status.idle":"2024-04-11T15:24:09.533849Z","shell.execute_reply.started":"2024-04-11T15:24:08.931353Z","shell.execute_reply":"2024-04-11T15:24:09.532837Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                           agent_prompt  \\\n0      sentence is: Pierre Vinken, 61 years old, wil...   \n1      sentence is: Mr. Vinken is chairman of Elsevi...   \n2      sentence is: Rudolph Agnew, 55 years old and ...   \n3      sentence is: A form of asbestos once used * *...   \n4      sentence is: A form of asbestos once used * *...   \n...                                                 ...   \n9347   sentence is: Trinity Industries Inc. said 0 i...   \n9348   sentence is: Trinity Industries Inc. said 0 i...   \n9349   sentence is: Terms weren't disclosed *-1. fin...   \n9350   sentence is: Trinity said 0 it plans *-1 to b...   \n9351   sentence is: Trinity said 0 it plans *-1 to b...   \n\n                             agent  \\\n0     Pierre Vinken, 61 years old,   \n1                            group   \n2                                    \n3                                    \n4                                *   \n...                            ...   \n9347                            it   \n9348                          it *   \n9349                                 \n9350                       Trinity   \n9351                            it   \n\n                                          target_prompt  \\\n0      sentence is: Pierre Vinken, 61 years old, wil...   \n1      sentence is: Mr. Vinken is chairman of Elsevi...   \n2      sentence is: Rudolph Agnew, 55 years old and ...   \n3      sentence is: A form of asbestos once used * *...   \n4      sentence is: A form of asbestos once used * *...   \n...                                                 ...   \n9347   sentence is: Trinity Industries Inc. said 0 i...   \n9348   sentence is: Trinity Industries Inc. said 0 i...   \n9349   sentence is: Terms weren't disclosed *-1. fin...   \n9350   sentence is: Trinity said 0 it plans *-1 to b...   \n9351   sentence is: Trinity said 0 it plans *-1 to b...   \n\n                                                 target  \n0                                             the board  \n1                                                        \n2     Rudolph Agnew, 55 years old and former chairma...  \n3                                  A form of asbestos *  \n4                                Kent cigarette filters  \n...                                                 ...  \n9347  a preliminary agreement * to sell 500 railcar ...  \n9348                              500 railcar platforms  \n9349                                          Terms *-1  \n9350  0 it plans *-1 to begin delivery in the first ...  \n9351  *-1 to begin delivery in the first quarter of ...  \n\n[9352 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>agent_prompt</th>\n      <th>agent</th>\n      <th>target_prompt</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sentence is: Pierre Vinken, 61 years old, wil...</td>\n      <td>Pierre Vinken, 61 years old,</td>\n      <td>sentence is: Pierre Vinken, 61 years old, wil...</td>\n      <td>the board</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sentence is: Mr. Vinken is chairman of Elsevi...</td>\n      <td>group</td>\n      <td>sentence is: Mr. Vinken is chairman of Elsevi...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sentence is: Rudolph Agnew, 55 years old and ...</td>\n      <td></td>\n      <td>sentence is: Rudolph Agnew, 55 years old and ...</td>\n      <td>Rudolph Agnew, 55 years old and former chairma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sentence is: A form of asbestos once used * *...</td>\n      <td></td>\n      <td>sentence is: A form of asbestos once used * *...</td>\n      <td>A form of asbestos *</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sentence is: A form of asbestos once used * *...</td>\n      <td>*</td>\n      <td>sentence is: A form of asbestos once used * *...</td>\n      <td>Kent cigarette filters</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9347</th>\n      <td>sentence is: Trinity Industries Inc. said 0 i...</td>\n      <td>it</td>\n      <td>sentence is: Trinity Industries Inc. said 0 i...</td>\n      <td>a preliminary agreement * to sell 500 railcar ...</td>\n    </tr>\n    <tr>\n      <th>9348</th>\n      <td>sentence is: Trinity Industries Inc. said 0 i...</td>\n      <td>it *</td>\n      <td>sentence is: Trinity Industries Inc. said 0 i...</td>\n      <td>500 railcar platforms</td>\n    </tr>\n    <tr>\n      <th>9349</th>\n      <td>sentence is: Terms weren't disclosed *-1. fin...</td>\n      <td></td>\n      <td>sentence is: Terms weren't disclosed *-1. fin...</td>\n      <td>Terms *-1</td>\n    </tr>\n    <tr>\n      <th>9350</th>\n      <td>sentence is: Trinity said 0 it plans *-1 to b...</td>\n      <td>Trinity</td>\n      <td>sentence is: Trinity said 0 it plans *-1 to b...</td>\n      <td>0 it plans *-1 to begin delivery in the first ...</td>\n    </tr>\n    <tr>\n      <th>9351</th>\n      <td>sentence is: Trinity said 0 it plans *-1 to b...</td>\n      <td>it</td>\n      <td>sentence is: Trinity said 0 it plans *-1 to b...</td>\n      <td>*-1 to begin delivery in the first quarter of ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9352 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Sample size (60% of total rows)\ntrain_size = int(0.6 * len(srl_df))\ntest_size = int(0.2 * len(srl_df))\n\n\n# Select 60% of the DataFrame randomly\nsrl_df_sampled = srl_df.sample(sample_size, random_state=42)\n\nsrl_train_dataset = CustomDataset(srl_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nsrl_train_data_loader = DataLoader(srl_train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\nsrl_test_dataset = ","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:24:13.465989Z","iopub.execute_input":"2024-04-11T15:24:13.466812Z","iopub.status.idle":"2024-04-11T15:24:13.471462Z","shell.execute_reply.started":"2024-04-11T15:24:13.46678Z","shell.execute_reply":"2024-04-11T15:24:13.470495Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_data(srl_train_data_loader, )","metadata":{"execution":{"iopub.status.busy":"2024-04-11T15:41:28.194134Z","iopub.execute_input":"2024-04-11T15:41:28.195166Z","iopub.status.idle":"2024-04-11T15:43:44.746685Z","shell.execute_reply.started":"2024-04-11T15:41:28.195125Z","shell.execute_reply":"2024-04-11T15:43:44.745353Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrl_train_data_loader\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mtrain_data\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     30\u001b[0m     target_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 33\u001b[0m f1_4_target \u001b[38;5;241m=\u001b[39m evaluate_model(model, \u001b[43mval_data_loader\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m f1_4_agent \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_data_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(losses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f1 for target:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_4_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, f1 for agent:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_4_agent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m end of epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'val_data_loader' is not defined"],"ename":"NameError","evalue":"name 'val_data_loader' is not defined","output_type":"error"}]},{"cell_type":"code","source":"target_accuracy = evaluate_model(model, test_data_loader, 'target')\nagent_accuracy = evaluate_model(model, test_data_loader, 'agent')\nprint(f'f1 Agent: {agent_accuracy}. f1 Target: {target_accuracy}\\n\\n----------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}