{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":4251,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3045}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:58:43.160910Z","iopub.execute_input":"2023-11-21T14:58:43.161735Z","iopub.status.idle":"2023-11-21T14:59:07.364063Z","shell.execute_reply.started":"2023-11-21T14:58:43.161674Z","shell.execute_reply":"2023-11-21T14:59:07.362870Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### importing libraries ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:59:07.366280Z","iopub.execute_input":"2023-11-21T14:59:07.366587Z","iopub.status.idle":"2023-11-21T14:59:12.895912Z","shell.execute_reply.started":"2023-11-21T14:59:07.366556Z","shell.execute_reply":"2023-11-21T14:59:12.895116Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#defining general valriables throughout the whole notebook\nEPOCH = 10\nbatch_size = 16\nmax_input_length = 64\nmax_label_length = 8\nt5_small = \"google/flan-t5-small\"","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:59:12.896995Z","iopub.execute_input":"2023-11-21T14:59:12.897382Z","iopub.status.idle":"2023-11-21T14:59:12.902250Z","shell.execute_reply.started":"2023-11-21T14:59:12.897356Z","shell.execute_reply":"2023-11-21T14:59:12.900985Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(t5_small)\nmodel = T5ForConditionalGeneration.from_pretrained(t5_small).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:59:12.904819Z","iopub.execute_input":"2023-11-21T14:59:12.905763Z","iopub.status.idle":"2023-11-21T14:59:20.181577Z","shell.execute_reply.started":"2023-11-21T14:59:12.905705Z","shell.execute_reply":"2023-11-21T14:59:20.180744Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b895474700c400baa28209179ebffa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c0ad5b251b244e8a069f6d11f24f99e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ad7803d6b6e4f9ab57c623a170baf39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e49729131f497e84ee41bf22208390"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8f42951053f4ccab7361be548bce6e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcbea9022535419ca91170c3ba18dc28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b20d7bea8f0493da305041f9e2cc7a8"}},"metadata":{}}]},{"cell_type":"markdown","source":"### reading dataset and cleaning it","metadata":{}},{"cell_type":"code","source":"def get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:59:20.182782Z","iopub.execute_input":"2023-11-21T14:59:20.183077Z","iopub.status.idle":"2023-11-21T14:59:20.189712Z","shell.execute_reply.started":"2023-11-21T14:59:20.183050Z","shell.execute_reply":"2023-11-21T14:59:20.188850Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### getting training data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-21T14:59:20.191562Z","iopub.execute_input":"2023-11-21T14:59:20.192139Z","iopub.status.idle":"2023-11-21T14:59:20.285274Z","shell.execute_reply.started":"2023-11-21T14:59:20.192105Z","shell.execute_reply":"2023-11-21T14:59:20.284371Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     The Kimberley Provincial Hospital said it woul...   \n1     Saeed said indications were that those tests w...   \n2     He said it was his opinion that the patient --...   \n3     The woman was admitted to the hospital on Satu...   \n4     `` Since our technical equipment is far from p...   \n...                                                 ...   \n2444  Benjamin Franklin Federal Savings & Loan Assoc...   \n2445  thrift said the restructuring should help it m...   \n2446  Details of the restructuring wo n't be made fi...   \n2447  Jay Stevens , an analyst with Dean Witter Reyn...   \n2448  company to earn 35 cents a share for the quart...   \n\n                                                    orl  \\\n0     [[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...   \n1     [[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...   \n2     [[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n3     [[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...   \n4     [[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...   \n...                                                 ...   \n2444           [[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]   \n2445          [[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]   \n2446   [[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]   \n2447   [[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]   \n2448  [[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]   \n\n                                               sep_sent  \n0     [The, Kimberley, Provincial, Hospital, said, i...  \n1     [Saeed, said, indications, were, that, those, ...  \n2     [He, said, it, was, his, opinion, that, the, p...  \n3     [The, woman, was, admitted, to, the, hospital,...  \n4     [``, Since, our, technical, equipment, is, far...  \n...                                                 ...  \n2444  [Benjamin, Franklin, Federal, Savings, &, Loan...  \n2445  [thrift, said, the, restructuring, should, hel...  \n2446  [Details, of, the, restructuring, wo, n't, be,...  \n2447  [Jay, Stevens, ,, an, analyst, with, Dean, Wit...  \n2448  [company, to, earn, 35, cents, a, share, for, ...  \n\n[2449 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>sep_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Kimberley Provincial Hospital said it woul...</td>\n      <td>[[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...</td>\n      <td>[The, Kimberley, Provincial, Hospital, said, i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saeed said indications were that those tests w...</td>\n      <td>[[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...</td>\n      <td>[Saeed, said, indications, were, that, those, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He said it was his opinion that the patient --...</td>\n      <td>[[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>[He, said, it, was, his, opinion, that, the, p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The woman was admitted to the hospital on Satu...</td>\n      <td>[[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...</td>\n      <td>[The, woman, was, admitted, to, the, hospital,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>`` Since our technical equipment is far from p...</td>\n      <td>[[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...</td>\n      <td>[``, Since, our, technical, equipment, is, far...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2444</th>\n      <td>Benjamin Franklin Federal Savings &amp; Loan Assoc...</td>\n      <td>[[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]</td>\n      <td>[Benjamin, Franklin, Federal, Savings, &amp;, Loan...</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>thrift said the restructuring should help it m...</td>\n      <td>[[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]</td>\n      <td>[thrift, said, the, restructuring, should, hel...</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>Details of the restructuring wo n't be made fi...</td>\n      <td>[[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]</td>\n      <td>[Details, of, the, restructuring, wo, n't, be,...</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>Jay Stevens , an analyst with Dean Witter Reyn...</td>\n      <td>[[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]</td>\n      <td>[Jay, Stevens, ,, an, analyst, with, Dean, Wit...</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>company to earn 35 cents a share for the quart...</td>\n      <td>[[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]</td>\n      <td>[company, to, earn, 35, cents, a, share, for, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2449 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to organize the data into separate columns\ndef organize_data(atributs, sentence):\n    AGENT, DSE, TARGET = '', '', ''\n    for sublist in atributs:\n        if sublist[-1] == 'AGENT':\n            start = int(sublist[2])\n            end = int(sublist[3] + 1)\n            AGENT += ' '.join(sentence[start:end]) + '|'\n        elif sublist[-1] == 'DSE':\n            start = int(sublist[0])\n            end = int(sublist[1] + 1)\n            DSE += ' '.join(sentence[start:end]) + '|'\n        elif sublist[-1] == 'TARGET':\n            start = int(sublist[2])\n            end = int(sublist[3] + 1)\n            TARGET += ' '.join(sentence[start:end]) + '|'\n    return AGENT, DSE, TARGET\n\n# Organize tarin data into diffrent columns\nfor i in range(len(df)):\n    agent, dse, target = organize_data(df['orl'][i], df['sep_sent'][i])\n    df.loc[i, 'agent'] = agent\n    df.loc[i, 'dse'] = dse\n    df.loc[i, 'target'] = target\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### getting evaluation data ready into dev_df and dividing elements into columns","metadata":{}},{"cell_type":"code","source":"dev_df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.dev0.conll.json\")\ndev_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(dev_df)):\n    agent, dse, target = organize_data(dev_df['orl'][i], dev_df['sep_sent'][i])\n    dev_df.loc[i, 'agent'] = agent\n    dev_df.loc[i, 'dse'] = dse\n    dev_df.loc[i, 'target'] = target\ndev_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T15:01:31.853969Z","iopub.execute_input":"2023-11-21T15:01:31.854615Z","iopub.status.idle":"2023-11-21T15:01:32.189707Z","shell.execute_reply.started":"2023-11-21T15:01:31.854578Z","shell.execute_reply":"2023-11-21T15:01:32.188767Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                            sentence  \\\n0  The owner though that the animal was suffering...   \n1  The owner put down the animal , although the v...   \n2  GATUNA , Rwanda , July 6 -LRB- AFP -RRB- - Pre...   \n3  The formerly close allies fell out in 1999 , t...   \n4  In March , Uganda declared Rwanda a hostile na...   \n5  The two countries have each accused the other ...   \n6  According to military experts , it is possible...   \n7  `` We hope that this will serve as an occasion...   \n8  The navy craft had approached the small boat t...   \n9  Merchant vessels have been warned to operate s...   \n\n                                                 orl  \\\n0  [[2, 2, 0, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...   \n1  [[10, 11, 8, 9, AGENT], [10, 11, 10, 11, DSE],...   \n2  [[30, 32, 30, 32, DSE], [30, 32, 33, 35, TARGET]]   \n3  [[4, 5, 0, 3, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n4  [[4, 4, 3, 3, AGENT], [4, 4, 4, 4, DSE], [4, 4...   \n5  [[3, 5, 3, 5, DSE], [3, 5, 6, 7, TARGET], [9, ...   \n6  [[0, 1, 0, 1, DSE], [0, 1, 2, 3, AGENT], [0, 1...   \n7  [[2, 2, 1, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...   \n8          [[8, 8, 8, 8, DSE], [8, 8, 9, 9, TARGET]]   \n9  [[2, 4, 0, 1, TARGET], [2, 4, 2, 4, DSE], [2, ...   \n\n                                            sep_sent  \\\n0  [The, owner, though, that, the, animal, was, s...   \n1  [The, owner, put, down, the, animal, ,, althou...   \n2  [GATUNA, ,, Rwanda, ,, July, 6, -LRB-, AFP, -R...   \n3  [The, formerly, close, allies, fell, out, in, ...   \n4  [In, March, ,, Uganda, declared, Rwanda, a, ho...   \n5  [The, two, countries, have, each, accused, the...   \n6  [According, to, military, experts, ,, it, is, ...   \n7  [``, We, hope, that, this, will, serve, as, an...   \n8  [The, navy, craft, had, approached, the, small...   \n9  [Merchant, vessels, have, been, warned, to, op...   \n\n                                               agent  \\\n0                                         The owner|   \n1                                           the vet|   \n2                                                      \n3  The formerly close allies|The formerly close a...   \n4                                            Uganda|   \n5                                                      \n6                                  military experts|   \n7                                                We|   \n8                                                      \n9                                                      \n\n                          dse  \\\n0                     though|   \n1              had forbidden|   \n2   soured relations between|   \n3  fell out|mounting rivalry|   \n4   declared|alleged|support|   \n5  have each accused|backing|   \n6               According to|   \n7                       hope|   \n8                   thinking|   \n9           have been warned|   \n\n                                              target  \n0                                        the animal|  \n1                                      him to do so|  \n2                      their neighbouring countries|  \n3                                              each|  \n4  Rwanda|Kigali|a rival to Museveni in a preside...  \n5                              the other|dissidents|  \n6  clashes will resume between the Taleban and UI...  \n7  this will serve as an occasion for LG to make ...  \n8                                                it|  \n9         Merchant vessels|being detected by rebels|  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>sep_sent</th>\n      <th>agent</th>\n      <th>dse</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The owner though that the animal was suffering...</td>\n      <td>[[2, 2, 0, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...</td>\n      <td>[The, owner, though, that, the, animal, was, s...</td>\n      <td>The owner|</td>\n      <td>though|</td>\n      <td>the animal|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The owner put down the animal , although the v...</td>\n      <td>[[10, 11, 8, 9, AGENT], [10, 11, 10, 11, DSE],...</td>\n      <td>[The, owner, put, down, the, animal, ,, althou...</td>\n      <td>the vet|</td>\n      <td>had forbidden|</td>\n      <td>him to do so|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GATUNA , Rwanda , July 6 -LRB- AFP -RRB- - Pre...</td>\n      <td>[[30, 32, 30, 32, DSE], [30, 32, 33, 35, TARGET]]</td>\n      <td>[GATUNA, ,, Rwanda, ,, July, 6, -LRB-, AFP, -R...</td>\n      <td></td>\n      <td>soured relations between|</td>\n      <td>their neighbouring countries|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The formerly close allies fell out in 1999 , t...</td>\n      <td>[[4, 5, 0, 3, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>[The, formerly, close, allies, fell, out, in, ...</td>\n      <td>The formerly close allies|The formerly close a...</td>\n      <td>fell out|mounting rivalry|</td>\n      <td>each|</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In March , Uganda declared Rwanda a hostile na...</td>\n      <td>[[4, 4, 3, 3, AGENT], [4, 4, 4, 4, DSE], [4, 4...</td>\n      <td>[In, March, ,, Uganda, declared, Rwanda, a, ho...</td>\n      <td>Uganda|</td>\n      <td>declared|alleged|support|</td>\n      <td>Rwanda|Kigali|a rival to Museveni in a preside...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The two countries have each accused the other ...</td>\n      <td>[[3, 5, 3, 5, DSE], [3, 5, 6, 7, TARGET], [9, ...</td>\n      <td>[The, two, countries, have, each, accused, the...</td>\n      <td></td>\n      <td>have each accused|backing|</td>\n      <td>the other|dissidents|</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>According to military experts , it is possible...</td>\n      <td>[[0, 1, 0, 1, DSE], [0, 1, 2, 3, AGENT], [0, 1...</td>\n      <td>[According, to, military, experts, ,, it, is, ...</td>\n      <td>military experts|</td>\n      <td>According to|</td>\n      <td>clashes will resume between the Taleban and UI...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>`` We hope that this will serve as an occasion...</td>\n      <td>[[2, 2, 1, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...</td>\n      <td>[``, We, hope, that, this, will, serve, as, an...</td>\n      <td>We|</td>\n      <td>hope|</td>\n      <td>this will serve as an occasion for LG to make ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The navy craft had approached the small boat t...</td>\n      <td>[[8, 8, 8, 8, DSE], [8, 8, 9, 9, TARGET]]</td>\n      <td>[The, navy, craft, had, approached, the, small...</td>\n      <td></td>\n      <td>thinking|</td>\n      <td>it|</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Merchant vessels have been warned to operate s...</td>\n      <td>[[2, 4, 0, 1, TARGET], [2, 4, 2, 4, DSE], [2, ...</td>\n      <td>[Merchant, vessels, have, been, warned, to, op...</td>\n      <td></td>\n      <td>have been warned|</td>\n      <td>Merchant vessels|being detected by rebels|</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['sentence'] = df['sentence'].astype(str).apply(lambda x: 'find expression of the sentence: ' + x)\ndev_df['sentence'] = df['sentence'].astype(str).apply(lambda x: 'find expression of the sentence: ' + x)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T15:03:59.887214Z","iopub.execute_input":"2023-11-21T15:03:59.887914Z","iopub.status.idle":"2023-11-21T15:03:59.902518Z","shell.execute_reply.started":"2023-11-21T15:03:59.887869Z","shell.execute_reply":"2023-11-21T15:03:59.901526Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data['sentence'][idx]\n        agent = self.data['agent'][idx]\n        dse = self.data['dse'][idx]\n        target = self.data['target'][idx]\n        text_encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        #agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #dse\n        dse_encoding = self.tokenizer(dse, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            #text\n            'input_ids': text_encoding['input_ids'].squeeze(),\n            'attention_mask': text_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #dse\n            'dse_id': dse_encoding['input_ids'].squeeze(),\n            'dse_mask': dse_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"execution":{"iopub.status.busy":"2023-11-21T15:04:19.017346Z","iopub.execute_input":"2023-11-21T15:04:19.017733Z","iopub.status.idle":"2023-11-21T15:04:19.028954Z","shell.execute_reply.started":"2023-11-21T15:04:19.017688Z","shell.execute_reply":"2023-11-21T15:04:19.027960Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def cal_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n\n    true_positives = 0\n    false_positives = 0\n    false_negatives = 0\n    threshold = 0.5\n    with torch.no_grad():\n        actual_list, prediction_list = [], []\n        for batch in dataloader:\n            # Move data to the specified device\n            batch = {key: value.to('cuda') for key, value in batch.items()}\n\n            # Forward pass\n            input_id = batch['input_ids']\n            attention_mask = batch['attention_mask']\n            target_id = batch['dse_id']\n            \n            output = model.generate(input_id)\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output[0]]\n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in target_id]\n            print(f'predicted: {preds},\\n actuals: {actuals}, end of batch +++++++++ \\n')\n            actual_list.extend(actuals)\n            prediction_list.extend(preds)\n\n#     # Calculate precision, recall, and F1-score\n#     precision = true_positives / max((true_positives + false_positives), 1e-10)\n#     recall = true_positives / max((true_positives + false_negatives), 1e-10)\n#     f1_score = 2 * (precision * recall) / max((precision + recall), 1e-10)\n    return 0\nevaluate_model(model, val_data_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a data loader\ntrain_dataset = CustomDataset(df, tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\ntrain_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataset = CustomDataset(df, tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\nval_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n\n# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T16:03:16.182034Z","iopub.execute_input":"2023-11-21T16:03:16.182818Z","iopub.status.idle":"2023-11-21T16:03:16.191972Z","shell.execute_reply.started":"2023-11-21T16:03:16.182781Z","shell.execute_reply":"2023-11-21T16:03:16.191078Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCH):\n    losses = []\n    print(epoch)\n    for batch in train_data_loader:\n        inputs = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        dse_id = batch['dse_id']\n        dse_mask = batch['dse_mask']\n\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask, labels=dse_id)\n        loss = outputs.loss\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    accuracy = evaluate_model(model, val_data_loader)\n    print(np.mean(losses), accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T16:03:17.307106Z","iopub.execute_input":"2023-11-21T16:03:17.307480Z","iopub.status.idle":"2023-11-21T16:03:33.019475Z","shell.execute_reply.started":"2023-11-21T16:03:17.307447Z","shell.execute_reply":"2023-11-21T16:03:33.018209Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 17\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(losses), accuracy)\n","Cell \u001b[0;32mIn[28], line 24\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     21\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(outputs\u001b[38;5;241m.\u001b[39mlogits) \u001b[38;5;241m>\u001b[39m threshold\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Update true_positives, false_positives, and false_negatives\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m true_positives \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdse_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m false_positives \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdse_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     26\u001b[0m false_negatives \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdse_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32128) must match the size of tensor b (8) at non-singleton dimension 2"],"ename":"RuntimeError","evalue":"The size of tensor a (32128) must match the size of tensor b (8) at non-singleton dimension 2","output_type":"error"}]},{"cell_type":"code","source":"input_text = \"find expression of the sentence: The Palestinians want nothing from Washington but to understand their cause and stand beside right and justice .\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}