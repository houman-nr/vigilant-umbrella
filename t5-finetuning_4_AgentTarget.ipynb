{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":4251,"sourceType":"modelInstanceVersion","modelInstanceId":3045}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/houmannorasteh/fork-of-t5-fine-tuning?scriptVersionId=164878208\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:12:22.492442Z","iopub.execute_input":"2024-02-29T13:12:22.492725Z","iopub.status.idle":"2024-02-29T13:12:48.949966Z","shell.execute_reply.started":"2024-02-29T13:12:22.492698Z","shell.execute_reply":"2024-02-29T13:12:48.94892Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### importing libraries ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nfrom itertools import zip_longest","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:12:48.951797Z","iopub.execute_input":"2024-02-29T13:12:48.952087Z","iopub.status.idle":"2024-02-29T13:12:55.83199Z","shell.execute_reply.started":"2024-02-29T13:12:48.95206Z","shell.execute_reply":"2024-02-29T13:12:55.83104Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### defining general variables","metadata":{}},{"cell_type":"code","source":"#defining global valriables throughout the whole notebook\nEPOCH = 10\nBATCH_SIZE = 16\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:12:55.833193Z","iopub.execute_input":"2024-02-29T13:12:55.833662Z","iopub.status.idle":"2024-02-29T13:12:55.838545Z","shell.execute_reply.started":"2024-02-29T13:12:55.833634Z","shell.execute_reply":"2024-02-29T13:12:55.837442Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:12:55.840786Z","iopub.execute_input":"2024-02-29T13:12:55.841089Z","iopub.status.idle":"2024-02-29T13:13:01.542931Z","shell.execute_reply.started":"2024-02-29T13:12:55.841062Z","shell.execute_reply":"2024-02-29T13:13:01.541911Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a7a8904e347413b914d04a12fe5b82f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"493f082fdc304838b658b4a17246a56f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d05a81556ef4f2c85edb550e33e23cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"569c59290b7443a98328f88200f4850d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48f651fb32fd4a80bbe8a0ff8626263a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55292b21715418ab62ee973bad3fe07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2eac3be5384a04982cf27b0701392a"}},"metadata":{}}]},{"cell_type":"markdown","source":"### reading dataset and cleaning it","metadata":{}},{"cell_type":"code","source":"# a funciton to read data off of a database link is here to help getting and organizing data into dataframes\ndef get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe\n\n# this function is to make a list of the said attribute for later iterations\ndef list_of(attributes, requested_atr):\n    requested_list = []\n    for sublist in attributes:\n        if sublist[-1] == requested_atr:\n            requested_list.append(sublist)\n    return requested_list\n\n# this function was made to find target(s)/agent(s) of a dse according to list of attributes\ndef organize_data(attributes, sentence):\n    AGENT, DSE, TARGET = '', '', ''\n    target_flag, agent_flag = False, False\n    for sublist in attributes:\n        if sublist[-1] == 'DSE':\n            dse_start = int(sublist[0])\n            dse_end = int(sublist[1] + 1)\n            DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n            \n            \n            # looking for the targets and agents of this dse that we have found\n            target_flag = False\n            for sub_sublist in list_of(attributes, 'TARGET'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    target_start = int(sub_sublist[2])\n                    target_end = int(sub_sublist[3] + 1)\n                    TARGET += ' '.join(sentence[target_start:target_end]) + '|'\n                    target_flag = True\n            if not target_flag:\n                TARGET += ' |'\n            \n            agent_flag = False\n            for sub_sublist in list_of(attributes, 'AGENT'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    agent_start = int(sub_sublist[2])\n                    agent_end = int(sub_sublist[3] + 1)\n                    AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n                    agent_flag = True\n            if not agent_flag:\n                AGENT += ' |'\n    return AGENT, DSE, TARGET","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:13:01.544304Z","iopub.execute_input":"2024-02-29T13:13:01.544731Z","iopub.status.idle":"2024-02-29T13:13:01.558888Z","shell.execute_reply.started":"2024-02-29T13:13:01.544704Z","shell.execute_reply":"2024-02-29T13:13:01.557894Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### getting training data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\n\n# Organize tarin data into diffrent columns\n# for each dse, function will dicide if it has target(s)/agent(s) and divides them with <\" | \">\nfor i in range(len(df)):\n    agent, dse, target = organize_data(df['orl'][i], df['sep_sent'][i])\n    df.loc[i, 'agent'] = agent\n    df.loc[i, 'dse'] = dse\n    df.loc[i, 'target'] = target\n\ndf.drop(columns='sep_sent')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:13:01.560007Z","iopub.execute_input":"2024-02-29T13:13:01.560322Z","iopub.status.idle":"2024-02-29T13:13:02.471274Z","shell.execute_reply.started":"2024-02-29T13:13:01.560296Z","shell.execute_reply":"2024-02-29T13:13:02.470201Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     The Kimberley Provincial Hospital said it woul...   \n1     Saeed said indications were that those tests w...   \n2     He said it was his opinion that the patient --...   \n3     The woman was admitted to the hospital on Satu...   \n4     `` Since our technical equipment is far from p...   \n...                                                 ...   \n2444  Benjamin Franklin Federal Savings & Loan Assoc...   \n2445  thrift said the restructuring should help it m...   \n2446  Details of the restructuring wo n't be made fi...   \n2447  Jay Stevens , an analyst with Dean Witter Reyn...   \n2448  company to earn 35 cents a share for the quart...   \n\n                                                    orl  \\\n0     [[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...   \n1     [[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...   \n2     [[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n3     [[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...   \n4     [[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...   \n...                                                 ...   \n2444           [[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]   \n2445          [[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]   \n2446   [[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]   \n2447   [[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]   \n2448  [[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]   \n\n                                   agent                   dse  \\\n0     The Kimberley Provincial Hospital|  would probably know|   \n1                                 Saeed|                 said|   \n2                                    He|          his opinion|   \n3                             The woman|          complaining|   \n4                               Nazarov|                 said|   \n...                                  ...                   ...   \n2444                                 it|                plans|   \n2445                                   |                 said|   \n2446                         regulators|              approve|   \n2447                                 he|             expected|   \n2448                                   |                 said|   \n\n                                            target  \n0     whether one of its patients had Congo Fever|  \n1                                     those tests|  \n2                          the patient -- a woman|  \n3                              severe joint pains|  \n4                      our technical equipment|we|  \n...                                            ...  \n2444                                             |  \n2445                            the restructuring|  \n2446                                             |  \n2447                                             |  \n2448                    the firm 's weaker profit|  \n\n[2449 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>agent</th>\n      <th>dse</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Kimberley Provincial Hospital said it woul...</td>\n      <td>[[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...</td>\n      <td>The Kimberley Provincial Hospital|</td>\n      <td>would probably know|</td>\n      <td>whether one of its patients had Congo Fever|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saeed said indications were that those tests w...</td>\n      <td>[[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...</td>\n      <td>Saeed|</td>\n      <td>said|</td>\n      <td>those tests|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He said it was his opinion that the patient --...</td>\n      <td>[[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>He|</td>\n      <td>his opinion|</td>\n      <td>the patient -- a woman|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The woman was admitted to the hospital on Satu...</td>\n      <td>[[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...</td>\n      <td>The woman|</td>\n      <td>complaining|</td>\n      <td>severe joint pains|</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>`` Since our technical equipment is far from p...</td>\n      <td>[[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...</td>\n      <td>Nazarov|</td>\n      <td>said|</td>\n      <td>our technical equipment|we|</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2444</th>\n      <td>Benjamin Franklin Federal Savings &amp; Loan Assoc...</td>\n      <td>[[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]</td>\n      <td>it|</td>\n      <td>plans|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>thrift said the restructuring should help it m...</td>\n      <td>[[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]</td>\n      <td>|</td>\n      <td>said|</td>\n      <td>the restructuring|</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>Details of the restructuring wo n't be made fi...</td>\n      <td>[[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]</td>\n      <td>regulators|</td>\n      <td>approve|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>Jay Stevens , an analyst with Dean Witter Reyn...</td>\n      <td>[[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]</td>\n      <td>he|</td>\n      <td>expected|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>company to earn 35 cents a share for the quart...</td>\n      <td>[[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]</td>\n      <td>|</td>\n      <td>said|</td>\n      <td>the firm 's weaker profit|</td>\n    </tr>\n  </tbody>\n</table>\n<p>2449 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### getting evaluation data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"dev_df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.dev0.conll.json\")\n\nfor i in range(len(dev_df)):\n    agent, dse, target = organize_data(dev_df['orl'][i], dev_df['sep_sent'][i])\n    dev_df.loc[i, 'agent'] = agent\n    dev_df.loc[i, 'dse'] = dse\n    dev_df.loc[i, 'target'] = target","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:29:29.640075Z","iopub.execute_input":"2024-02-29T13:29:29.640981Z","iopub.status.idle":"2024-02-29T13:29:29.982564Z","shell.execute_reply.started":"2024-02-29T13:29:29.640946Z","shell.execute_reply":"2024-02-29T13:29:29.98166Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def pipeDivider(pipedString):\n    listOfItems = []\n    listOfItems = pipedString.split('|')[:-1]\n    return listOfItems","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:13:19.371147Z","iopub.execute_input":"2024-02-29T13:13:19.372422Z","iopub.status.idle":"2024-02-29T13:13:19.377706Z","shell.execute_reply.started":"2024-02-29T13:13:19.372373Z","shell.execute_reply":"2024-02-29T13:13:19.376676Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# function which will write prompt for the model according to the sentence and the items in it\ndef create_prompt(input_df):\n    output_df = pd.DataFrame(columns=['target_prompt', 'agent_prompt', 'target', 'agent'])\n    for i in range(len(input_df)):\n        dse_list, target_list, agent_list = [], [], []\n        dse_list = pipeDivider(str(input_df.iloc[i]['dse']))\n        target_list = pipeDivider(str(input_df.iloc[i]['target']))\n        agent_list = pipeDivider(str(input_df.iloc[i]['agent']))\n        for j in range(len(dse_list)):\n            last_row = int(len(output_df))+1\n            output_df.loc[last_row, 'target_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find target for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'agent_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find agent for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'target'] = target_list[j]\n            output_df.loc[last_row, 'agent'] = agent_list[j]\n    return output_df","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:24:50.771434Z","iopub.execute_input":"2024-02-29T13:24:50.771853Z","iopub.status.idle":"2024-02-29T13:24:50.78034Z","shell.execute_reply.started":"2024-02-29T13:24:50.771821Z","shell.execute_reply":"2024-02-29T13:24:50.779027Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### change the sentence and dse into a prompt according to information in that row","metadata":{}},{"cell_type":"code","source":"dev_df = create_prompt(dev_df)\ntrain_df = create_prompt(df)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T13:29:35.56288Z","iopub.execute_input":"2024-02-29T13:29:35.563769Z","iopub.status.idle":"2024-02-29T13:29:39.74147Z","shell.execute_reply.started":"2024-02-29T13:29:35.563724Z","shell.execute_reply":"2024-02-29T13:29:39.740617Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ndev_df = dev_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:24:28.206603Z","iopub.execute_input":"2024-02-29T14:24:28.207002Z","iopub.status.idle":"2024-02-29T14:24:28.212725Z","shell.execute_reply.started":"2024-02-29T14:24:28.206969Z","shell.execute_reply":"2024-02-29T14:24:28.211714Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"print(train_df.loc[0])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:24:03.145409Z","iopub.execute_input":"2024-02-29T14:24:03.14624Z","iopub.status.idle":"2024-02-29T14:24:03.151964Z","shell.execute_reply.started":"2024-02-29T14:24:03.146194Z","shell.execute_reply":"2024-02-29T14:24:03.151005Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"target_prompt    Sentence is: The Kimberley Provincial Hospital...\nagent_prompt     Sentence is: The Kimberley Provincial Hospital...\ntarget                 whether one of its patients had Congo Fever\nagent                            The Kimberley Provincial Hospital\nName: 0, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        agent_prompt = self.data['agent_prompt'][idx]\n        target_prompt = self.data['target_prompt'][idx]\n        agent = self.data['agent'][idx]\n        target = self.data['target'][idx]\n        # tokenizing agent prompt\n        agent_prompt_encoding = self.tokenizer(agent_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing target prompt\n        target_prompt_encoding = self.tokenizer(target_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        # tokenizing target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent prompt\n            'agent_input_id': agent_prompt_encoding['input_ids'].squeeze(),\n            'agent_attention_mask': agent_prompt_encoding['attention_mask'].squeeze(),\n            # target prompt\n            'target_input_id': target_prompt_encoding['input_ids'].squeeze(),\n            'target_attention_mask': target_prompt_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:24:54.593762Z","iopub.execute_input":"2024-02-29T14:24:54.594232Z","iopub.status.idle":"2024-02-29T14:24:54.607423Z","shell.execute_reply.started":"2024-02-29T14:24:54.594178Z","shell.execute_reply":"2024-02-29T14:24:54.606224Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Create a data loader for train dataframe \ntrain_dataset = CustomDataset(train_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for evaluation dataframe\nval_dataset = CustomDataset(dev_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:24:56.907666Z","iopub.execute_input":"2024-02-29T14:24:56.908089Z","iopub.status.idle":"2024-02-29T14:24:56.919565Z","shell.execute_reply.started":"2024-02-29T14:24:56.908046Z","shell.execute_reply":"2024-02-29T14:24:56.918236Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def f1_calculator(pred_list, actual_list):\n    cleaned_pred, cleaned_actual = [], []\n    matched = 0\n    for i in range(len(pred_list)):\n        for j in range(len(actual_list)):\n            if actual_list[j] in pred_list:\n                matched += 1\n        cleaned_pred.extend(pred_list)\n        cleaned_actual.extend(actual_list)\n    \n    prediction_len = len(cleaned_pred)\n    actual_len = len(cleaned_actual)\n    print(f'matched: {matched}, prediction_len:{prediction_len}, actual_len:{actual_len} \\n')\n    try:\n        precision = (matched / prediction_len)\n        recall = (matched / actual_len)\n        f1 = (2 * (precision * recall)) / (precision + recall)\n    except:\n        f1 = 0\n    return f1","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:34:23.007604Z","iopub.execute_input":"2024-02-29T14:34:23.008557Z","iopub.status.idle":"2024-02-29T14:34:23.015832Z","shell.execute_reply.started":"2024-02-29T14:34:23.008521Z","shell.execute_reply":"2024-02-29T14:34:23.014738Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, prompt_type):\n    if prompt_type == 'target':\n        id_type = 'target_input_id'\n        attention_type = 'target_attention_mask'\n        output_type = 'target_id'\n    elif prompt_type == 'agent':\n        id_type = 'agent_input_id'\n        attention_type = 'agent_attention_mask'\n        output_type = 'agent_id'\n    \n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        true_counted, prediction_counted, actual_counted = 0,0,0\n        matched, prediction_len, actual_len = 0,0,0\n        actual_list, prediction_list, f1 = [], [], []\n        for batch_idx, batch in enumerate(dataloader):\n            # Move data to the specified device\n            # batch = {key: value.to('cuda') for key, value in batch.items()}\n\n            # Forward pass\n            ids = batch[id_type]\n            mask = batch[attention_type]\n            output_id = batch[output_type]\n            \n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output_id]\n            \n            generated_output = generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=64, \n              )\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_output]\n            \n            actual_list.extend(actuals)\n            prediction_list.extend(preds)\n    return f1_calculator(prediction_list, actual_list)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:34:24.462856Z","iopub.execute_input":"2024-02-29T14:34:24.463237Z","iopub.status.idle":"2024-02-29T14:34:24.473619Z","shell.execute_reply.started":"2024-02-29T14:34:24.463187Z","shell.execute_reply":"2024-02-29T14:34:24.472539Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCH):\n    losses = []\n    for batch in train_data_loader:\n        \n        agent_input = batch['agent_input_id']\n        agent_attention_mask = batch['agent_attention_mask']\n        \n        target_input = batch['target_input_id']\n        target_attention_mask = batch['target_attention_mask']\n        \n        agent_id = batch['agent_id']\n        agent_mask = batch['agent_mask']\n        \n        target_id = batch['target_id']\n        target_mask = batch['target_mask']\n        \n        optimizer.zero_grad()\n        \n        agent_output = model(agent_input, attention_mask=agent_attention_mask, labels=agent_id)\n        target_output = model(target_input, attention_mask=target_attention_mask, labels=target_id)\n        \n        agent_loss = agent_output.loss\n        target_loss = target_output.loss\n        losses.append(agent_loss.item())\n        losses.append(target_loss.item())\n        \n        agent_loss.backward()\n        target_loss.backward()\n        optimizer.step()\n        \n    f1_4_target = evaluate_model(model, val_data_loader, 'target')\n    f1_4_agent = evaluate_model(model, val_data_loader, 'agent')\n    print(f'loss: {np.mean(losses)}, f1 validation for target:{f1_4_target}, f1 validation for agent:{f1_4_agent} \\n end of epoch{epoch}. \\n')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T14:34:25.536094Z","iopub.execute_input":"2024-02-29T14:34:25.536523Z","iopub.status.idle":"2024-02-29T14:55:43.492806Z","shell.execute_reply.started":"2024-02-29T14:34:25.536488Z","shell.execute_reply":"2024-02-29T14:55:43.491708Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"matched: 1466748, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1869651, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.2089297964713827, f1 validation for target:0.6441351888667992, f1 validation for agent:0.8210735586481114 \n end of epoch0. \n\nmatched: 1422987, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1816836, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.124608594321591, f1 validation for target:0.6249171636845593, f1 validation for agent:0.7978793903247183 \n end of epoch1. \n\nmatched: 1347537, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1771566, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.09487294737719489, f1 validation for target:0.5917826375082836, f1 validation for agent:0.777998674618953 \n end of epoch2. \n\nmatched: 1415442, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1786656, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.0819349395089079, f1 validation for target:0.6216037110669318, f1 validation for agent:0.7846255798542081 \n end of epoch3. \n\nmatched: 1400352, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1780620, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.07507597495197546, f1 validation for target:0.6149768058316766, f1 validation for agent:0.781974817760106 \n end of epoch4. \n\nmatched: 1471275, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1837962, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.07202876653423221, f1 validation for target:0.6461232604373758, f1 validation for agent:0.8071570576540756 \n end of epoch5. \n\nmatched: 1407897, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1782129, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.07534675605645681, f1 validation for target:0.6182902584493042, f1 validation for agent:0.7826375082836315 \n end of epoch6. \n\nmatched: 1401861, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1776093, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.07506270985484094, f1 validation for target:0.6156394963552021, f1 validation for agent:0.7799867461895295 \n end of epoch7. \n\nmatched: 1404879, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1797219, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.08080032006342268, f1 validation for target:0.6169648774022531, f1 validation for agent:0.7892644135188867 \n end of epoch8. \n\nmatched: 1376208, prediction_len:2277081, actual_len:2277081 \n\nmatched: 1806273, prediction_len:2277081, actual_len:2277081 \n\nloss: 0.0852483511334538, f1 validation for target:0.6043737574552683, f1 validation for agent:0.7932405566600398 \n end of epoch9. \n\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(EPOCH):\n    print(f'epoch: {epoch} \\n')\n    accuracy = evaluate_model(model, val_data_loader)\n    print(f'accuracy: {accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}