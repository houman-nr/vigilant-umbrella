{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":4251,"sourceType":"modelInstanceVersion","modelInstanceId":3045}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/houmannorasteh/fork-of-t5-fine-tuning?scriptVersionId=164693993\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-02-28T11:42:58.713803Z","iopub.execute_input":"2024-02-28T11:42:58.714203Z","iopub.status.idle":"2024-02-28T11:43:22.927175Z","shell.execute_reply.started":"2024-02-28T11:42:58.71417Z","shell.execute_reply":"2024-02-28T11:43:22.926017Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### importing libraries ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nfrom itertools import zip_longest","metadata":{"execution":{"iopub.status.busy":"2024-02-28T11:43:22.929215Z","iopub.execute_input":"2024-02-28T11:43:22.929528Z","iopub.status.idle":"2024-02-28T11:43:26.013039Z","shell.execute_reply.started":"2024-02-28T11:43:22.929499Z","shell.execute_reply":"2024-02-28T11:43:26.012044Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### defining general variables","metadata":{}},{"cell_type":"code","source":"#defining general valriables throughout the whole notebook\nEPOCH = 10\nbatch_size = 16\nmax_input_length = 64\nmax_label_length = 8\nMODEL_LINK = \"google/flan-t5-small\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T11:43:26.014357Z","iopub.execute_input":"2024-02-28T11:43:26.014834Z","iopub.status.idle":"2024-02-28T11:43:26.019433Z","shell.execute_reply.started":"2024-02-28T11:43:26.014805Z","shell.execute_reply":"2024-02-28T11:43:26.018553Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-02-28T11:43:26.020571Z","iopub.execute_input":"2024-02-28T11:43:26.020892Z","iopub.status.idle":"2024-02-28T11:43:27.955486Z","shell.execute_reply.started":"2024-02-28T11:43:26.020818Z","shell.execute_reply":"2024-02-28T11:43:27.954126Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### reading dataset and cleaning it","metadata":{}},{"cell_type":"code","source":"# a funciton to read data off of a database link\n\ndef get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe","metadata":{"execution":{"iopub.status.busy":"2024-02-28T11:48:18.295721Z","iopub.execute_input":"2024-02-28T11:48:18.296792Z","iopub.status.idle":"2024-02-28T11:48:18.303822Z","shell.execute_reply.started":"2024-02-28T11:48:18.296751Z","shell.execute_reply":"2024-02-28T11:48:18.302837Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### getting training data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-02-28T12:26:22.178175Z","iopub.execute_input":"2024-02-28T12:26:22.178991Z","iopub.status.idle":"2024-02-28T12:26:22.258758Z","shell.execute_reply.started":"2024-02-28T12:26:22.178957Z","shell.execute_reply":"2024-02-28T12:26:22.257769Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     The Kimberley Provincial Hospital said it woul...   \n1     Saeed said indications were that those tests w...   \n2     He said it was his opinion that the patient --...   \n3     The woman was admitted to the hospital on Satu...   \n4     `` Since our technical equipment is far from p...   \n...                                                 ...   \n2444  Benjamin Franklin Federal Savings & Loan Assoc...   \n2445  thrift said the restructuring should help it m...   \n2446  Details of the restructuring wo n't be made fi...   \n2447  Jay Stevens , an analyst with Dean Witter Reyn...   \n2448  company to earn 35 cents a share for the quart...   \n\n                                                    orl  \\\n0     [[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...   \n1     [[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...   \n2     [[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n3     [[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...   \n4     [[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...   \n...                                                 ...   \n2444           [[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]   \n2445          [[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]   \n2446   [[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]   \n2447   [[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]   \n2448  [[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]   \n\n                                               sep_sent  \n0     [The, Kimberley, Provincial, Hospital, said, i...  \n1     [Saeed, said, indications, were, that, those, ...  \n2     [He, said, it, was, his, opinion, that, the, p...  \n3     [The, woman, was, admitted, to, the, hospital,...  \n4     [``, Since, our, technical, equipment, is, far...  \n...                                                 ...  \n2444  [Benjamin, Franklin, Federal, Savings, &, Loan...  \n2445  [thrift, said, the, restructuring, should, hel...  \n2446  [Details, of, the, restructuring, wo, n't, be,...  \n2447  [Jay, Stevens, ,, an, analyst, with, Dean, Wit...  \n2448  [company, to, earn, 35, cents, a, share, for, ...  \n\n[2449 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>sep_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Kimberley Provincial Hospital said it woul...</td>\n      <td>[[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...</td>\n      <td>[The, Kimberley, Provincial, Hospital, said, i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saeed said indications were that those tests w...</td>\n      <td>[[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...</td>\n      <td>[Saeed, said, indications, were, that, those, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He said it was his opinion that the patient --...</td>\n      <td>[[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>[He, said, it, was, his, opinion, that, the, p...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The woman was admitted to the hospital on Satu...</td>\n      <td>[[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...</td>\n      <td>[The, woman, was, admitted, to, the, hospital,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>`` Since our technical equipment is far from p...</td>\n      <td>[[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...</td>\n      <td>[``, Since, our, technical, equipment, is, far...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2444</th>\n      <td>Benjamin Franklin Federal Savings &amp; Loan Assoc...</td>\n      <td>[[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]</td>\n      <td>[Benjamin, Franklin, Federal, Savings, &amp;, Loan...</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>thrift said the restructuring should help it m...</td>\n      <td>[[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]</td>\n      <td>[thrift, said, the, restructuring, should, hel...</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>Details of the restructuring wo n't be made fi...</td>\n      <td>[[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]</td>\n      <td>[Details, of, the, restructuring, wo, n't, be,...</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>Jay Stevens , an analyst with Dean Witter Reyn...</td>\n      <td>[[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]</td>\n      <td>[Jay, Stevens, ,, an, analyst, with, Dean, Wit...</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>company to earn 35 cents a share for the quart...</td>\n      <td>[[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]</td>\n      <td>[company, to, earn, 35, cents, a, share, for, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2449 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to organize the data into separate columns\ndef list_of(atributs, requested_atr):\n    requested_list = []\n    for sublist in atributs:\n        if sublist[-1] == requested_atr:\n            requested_list.append(sublist)\n    return requested_list\n\ndef organize_data(atributs, sentence):\n    AGENT, DSE, TARGET = '', '', ''\n    target_flag, agent_flag = False, False\n    for sublist in atributs:\n        if sublist[-1] == 'DSE':\n            dse_start = int(sublist[0])\n            dse_end = int(sublist[1] + 1)\n            DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n            \n            target_flag = False\n            # looking for the targets and agents of this dse\n            for sub_sublist in list_of(atributs, 'TARGET'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    target_start = int(sub_sublist[2])\n                    target_end = int(sub_sublist[3] + 1)\n                    TARGET += ' '.join(sentence[target_start:target_end]) + '|'\n                    target_flag = True\n            if not target_flag:\n                TARGET += ' |'\n            \n            agent_flag = False\n            for sub_sublist in list_of(atributs, 'AGENT'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    agent_start = int(sub_sublist[2])\n                    agent_end = int(sub_sublist[3] + 1)\n                    AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n                    agent_flag = True\n            if not agent_flag:\n                AGENT += ' |'\n    return AGENT, DSE, TARGET\n\n# Organize tarin data into diffrent columns\nfor i in range(len(df)):\n    agent, dse, target = organize_data(df['orl'][i], df['sep_sent'][i])\n    df.loc[i, 'agent'] = agent\n    df.loc[i, 'dse'] = dse\n    df.loc[i, 'target'] = target","metadata":{"execution":{"iopub.status.busy":"2024-02-28T12:26:37.327474Z","iopub.execute_input":"2024-02-28T12:26:37.328394Z","iopub.status.idle":"2024-02-28T12:26:38.067204Z","shell.execute_reply.started":"2024-02-28T12:26:37.328356Z","shell.execute_reply":"2024-02-28T12:26:38.066386Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(df.iloc[2435]['sentence'])\nprint(df.iloc[2435]['orl'])\nprint(f\"target:{df.iloc[2435]['target']}\")\nprint(f\"dse: {df.iloc[2435]['dse']}\")\nprint(f\"agent: {df.iloc[2435]['agent']}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T12:26:41.142235Z","iopub.execute_input":"2024-02-28T12:26:41.143152Z","iopub.status.idle":"2024-02-28T12:26:41.149663Z","shell.execute_reply.started":"2024-02-28T12:26:41.14309Z","shell.execute_reply":"2024-02-28T12:26:41.148654Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"The transaction has been approved by Kyle 's board , but requires the approval of the company 's shareholders .\n[[2, 4, 0, 1, 'TARGET'], [2, 4, 2, 4, 'DSE'], [2, 4, 6, 8, 'AGENT'], [13, 13, 13, 13, 'DSE'], [13, 13, 15, 18, 'AGENT']]\ntarget:The transaction| |\ndse: has been approved|approval|\nagent: Kyle 's board|the company 's shareholders|\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i in range(len(df)):\n#     if (int(len(df.iloc[i]['orl'])) >= 6):\n#         print(i)\n\n\nprint(df.iloc[2430]['sentence'])\nprint(df.iloc[2430]['orl'])\nprint(df.iloc[2430])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns='sep_sent')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pipeDivider(pipedString):\n    listOfItems = []\n    listOfItems = pipedString.split('|')[:-1]\n    return listOfItems","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# it is here to iterate over every single dse -inner loop- of every sentence of the database -outer loop-\n# (very inefficient, i know. i havn't figured out what to do yet)\ntrain_df = pd.DataFrame(columns=['target_prompt', 'agent_prompt', 'target', 'agent'])\n\nfor i in range(len(df)):\n    dse_list = []\n    dse_list = pipeDivider(str(df.iloc[i]['dse']))\n    target_list = pipeDivider(str(df.iloc[i]['target']))\n    agent_list = pipeDivider(str(df.iloc[i]['agent']))\n    for j in range(len(dse_list)):\n        last_row = int(len(train_df))+1\n        train_df.loc[last_row, 'target_prompt'] = f\"Sentence is: {df.iloc[i]['sentence']} Find target for this dse: {dse_list[j]}\"\n        train_df.loc[last_row, 'agent_prompt'] = f\"Sentence is: {df.iloc[i]['sentence']} Find agent for this dse: {dse_list[j]}\"\n        train_df.loc[last_row, 'target'] = target_list[j]\n        train_df.loc[last_row, 'agent'] = agent_list[j]\n\ntrain_df.head(-3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.iloc[3]['target_prompt'])\nprint(train_df.iloc[4]['target_prompt'])\nprint(train_df.iloc[5]['target_prompt'])\nprint(train_df.iloc[6]['target_prompt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data['sentence'][idx]\n        agent = self.data['agent'][idx]\n        dse = self.data['dse'][idx]\n        target = self.data['target'][idx]\n        text_encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        #agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #dse\n        dse_encoding = self.tokenizer(dse, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            #text\n            'input_ids': text_encoding['input_ids'].squeeze(),\n            'attention_mask': text_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #dse\n            'dse_id': dse_encoding['input_ids'].squeeze(),\n            'dse_mask': dse_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a data loader\ntrain_dataset = CustomDataset(df[:2500], tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\ntrain_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataset = CustomDataset(dev_df, tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\nval_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleaner(str_item):\n    final_string_list = []\n    string_list = str_item.split('|')\n    for i in string_list:\n        j = i.replace(' ', '')\n        if len(j) > 0:\n            # data cleaning\n            final_string_list.append(j)\n            \n    return final_string_list\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaner(\"a|b|  |\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_calculator(pred_list, actual_list):\n    cleaned_pred, cleaned_actual = [], []\n    matched = 0\n    for i in range(len(pred_list)):\n        pred_items = cleaner(pred_list[i])\n        actual_items = cleaner(actual_list[i])\n        # function:\n        for j in range(len(actual_items)):\n            print(actual_items[j])\n            if actual_items[j] in pred_items:\n                matched += 1\n                print(f'** actual ** \\n')\n        cleaned_pred.extend(pred_items)\n        cleaned_actual.extend(actual_items)\n    \n    prediction_len = len(cleaned_pred)\n    actual_len = len(cleaned_actual)\n    print(f'matched: {matched}, prediction_len:{prediction_len}, actual_len:{actual_len} \\n')\n    try:\n        precision = (matched / prediction_len)\n        recall = (matched / actual_len)\n        f1 = (2 * (precision * recall)) / (precision + recall)\n    except:\n        f1 = 0\n    return f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        true_counted, prediction_counted, actual_counted = 0,0,0\n        matched, prediction_len, actual_len = 0,0,0\n        actual_list, prediction_list, f1 = [], [], []\n        for batch_idx, batch in enumerate(dataloader):\n            # Move data to the specified device\n            # batch = {key: value.to('cuda') for key, value in batch.items()}\n\n            # Forward pass\n            ids = batch['input_ids']\n            mask = batch['attention_mask']\n            target_id = batch['dse_id']\n            \n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in target_id]\n            \n            output = generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=64, \n              )\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output]\n            \n            actual_list.extend(actuals)\n            prediction_list.extend(preds)\n    return f1_calculator(prediction_list, actual_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCH):\n    losses = []\n    print(f'epoch: {epoch} \\n')\n    for batch in train_data_loader:\n        inputs = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        dse_id = batch['dse_id']\n        dse_mask = batch['dse_mask']\n\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask, labels=dse_id)\n        loss = outputs.loss\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    f1 = evaluate_model(model, val_data_loader)\n    print(f'loss: {np.mean(losses)}, f1 validation:{f1} \\n end of epoch{epoch}. \\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCH):\n    print(f'epoch: {epoch} \\n')\n    accuracy = evaluate_model(model, val_data_loader)\n    print(f'accuracy: {accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = \"find expression of the sentence: The Palestinians want nothing from Washington but to understand their cause and stand beside right and justice .\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}