{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":4251,"sourceType":"modelInstanceVersion","modelInstanceId":3045}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/houmannorasteh/fork-of-t5-fine-tuning?scriptVersionId=164813194\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:15:00.360963Z","iopub.execute_input":"2024-02-29T07:15:00.361279Z","iopub.status.idle":"2024-02-29T07:15:27.967328Z","shell.execute_reply.started":"2024-02-29T07:15:00.361251Z","shell.execute_reply":"2024-02-29T07:15:27.966213Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### importing libraries ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nfrom itertools import zip_longest","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:15:27.969072Z","iopub.execute_input":"2024-02-29T07:15:27.969389Z","iopub.status.idle":"2024-02-29T07:15:37.866471Z","shell.execute_reply.started":"2024-02-29T07:15:27.969362Z","shell.execute_reply":"2024-02-29T07:15:37.86537Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### defining general variables","metadata":{}},{"cell_type":"code","source":"#defining global valriables throughout the whole notebook\nEPOCH = 10\nBATCH_SIZE = 16\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:15:37.867777Z","iopub.execute_input":"2024-02-29T07:15:37.868263Z","iopub.status.idle":"2024-02-29T07:15:37.872794Z","shell.execute_reply.started":"2024-02-29T07:15:37.86823Z","shell.execute_reply":"2024-02-29T07:15:37.871846Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:15:37.875816Z","iopub.execute_input":"2024-02-29T07:15:37.876098Z","iopub.status.idle":"2024-02-29T07:15:43.339311Z","shell.execute_reply.started":"2024-02-29T07:15:37.876073Z","shell.execute_reply":"2024-02-29T07:15:43.338493Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fec541bfdda34277895f12f60013761b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9308ed3ae2c04d9480999238136a41da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50d322f4e3414cddb8e85db20f57848e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d996270fe26424e9c37b60ea92c2248"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ae2e934bb04cc0afbd1258e05d662d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1439bd5a1f414913b2cbe6270cd28938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc850822e124496aff24ef90ca7da0a"}},"metadata":{}}]},{"cell_type":"markdown","source":"### reading dataset and cleaning it","metadata":{}},{"cell_type":"code","source":"# a funciton to read data off of a database link is here to help getting and organizing data into dataframes\ndef get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe\n\n# this function is to make a list of the said attribute for later iterations\ndef list_of(attributes, requested_atr):\n    requested_list = []\n    for sublist in attributes:\n        if sublist[-1] == requested_atr:\n            requested_list.append(sublist)\n    return requested_list\n\n# this function was made to find target(s)/agent(s) of a dse according to list of attributes\ndef organize_data(attributes, sentence):\n    AGENT, DSE, TARGET = '', '', ''\n    target_flag, agent_flag = False, False\n    for sublist in attributes:\n        if sublist[-1] == 'DSE':\n            dse_start = int(sublist[0])\n            dse_end = int(sublist[1] + 1)\n            DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n            \n            \n            # looking for the targets and agents of this dse that we have found\n            target_flag = False\n            for sub_sublist in list_of(attributes, 'TARGET'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    target_start = int(sub_sublist[2])\n                    target_end = int(sub_sublist[3] + 1)\n                    TARGET += ' '.join(sentence[target_start:target_end]) + '|'\n                    target_flag = True\n            if not target_flag:\n                TARGET += ' |'\n            \n            agent_flag = False\n            for sub_sublist in list_of(attributes, 'AGENT'):\n                if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                    agent_start = int(sub_sublist[2])\n                    agent_end = int(sub_sublist[3] + 1)\n                    AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n                    agent_flag = True\n            if not agent_flag:\n                AGENT += ' |'\n    return AGENT, DSE, TARGET","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:16:13.738451Z","iopub.execute_input":"2024-02-29T07:16:13.73947Z","iopub.status.idle":"2024-02-29T07:16:13.757231Z","shell.execute_reply.started":"2024-02-29T07:16:13.739426Z","shell.execute_reply":"2024-02-29T07:16:13.756302Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### getting training data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\n\n# Organize tarin data into diffrent columns\n# for each dse, function will dicide if it has target(s)/agent(s) and divides them with <\" | \">\nfor i in range(len(df)):\n    agent, dse, target = organize_data(df['orl'][i], df['sep_sent'][i])\n    df.loc[i, 'agent'] = agent\n    df.loc[i, 'dse'] = dse\n    df.loc[i, 'target'] = target\n\ndf.drop(columns='sep_sent')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:16:18.164226Z","iopub.execute_input":"2024-02-29T07:16:18.164919Z","iopub.status.idle":"2024-02-29T07:16:19.037676Z","shell.execute_reply.started":"2024-02-29T07:16:18.164886Z","shell.execute_reply":"2024-02-29T07:16:19.036667Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     The Kimberley Provincial Hospital said it woul...   \n1     Saeed said indications were that those tests w...   \n2     He said it was his opinion that the patient --...   \n3     The woman was admitted to the hospital on Satu...   \n4     `` Since our technical equipment is far from p...   \n...                                                 ...   \n2444  Benjamin Franklin Federal Savings & Loan Assoc...   \n2445  thrift said the restructuring should help it m...   \n2446  Details of the restructuring wo n't be made fi...   \n2447  Jay Stevens , an analyst with Dean Witter Reyn...   \n2448  company to earn 35 cents a share for the quart...   \n\n                                                    orl  \\\n0     [[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...   \n1     [[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...   \n2     [[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n3     [[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...   \n4     [[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...   \n...                                                 ...   \n2444           [[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]   \n2445          [[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]   \n2446   [[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]   \n2447   [[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]   \n2448  [[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]   \n\n                                   agent                   dse  \\\n0     The Kimberley Provincial Hospital|  would probably know|   \n1                                 Saeed|                 said|   \n2                                    He|          his opinion|   \n3                             The woman|          complaining|   \n4                               Nazarov|                 said|   \n...                                  ...                   ...   \n2444                                 it|                plans|   \n2445                                   |                 said|   \n2446                         regulators|              approve|   \n2447                                 he|             expected|   \n2448                                   |                 said|   \n\n                                            target  \n0     whether one of its patients had Congo Fever|  \n1                                     those tests|  \n2                          the patient -- a woman|  \n3                              severe joint pains|  \n4                      our technical equipment|we|  \n...                                            ...  \n2444                                             |  \n2445                            the restructuring|  \n2446                                             |  \n2447                                             |  \n2448                    the firm 's weaker profit|  \n\n[2449 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>agent</th>\n      <th>dse</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Kimberley Provincial Hospital said it woul...</td>\n      <td>[[6, 8, 0, 3, AGENT], [6, 8, 6, 8, DSE], [6, 8...</td>\n      <td>The Kimberley Provincial Hospital|</td>\n      <td>would probably know|</td>\n      <td>whether one of its patients had Congo Fever|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saeed said indications were that those tests w...</td>\n      <td>[[1, 1, 0, 0, AGENT], [1, 1, 1, 1, DSE], [1, 1...</td>\n      <td>Saeed|</td>\n      <td>said|</td>\n      <td>those tests|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He said it was his opinion that the patient --...</td>\n      <td>[[4, 5, 0, 0, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>He|</td>\n      <td>his opinion|</td>\n      <td>the patient -- a woman|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The woman was admitted to the hospital on Satu...</td>\n      <td>[[10, 10, 0, 1, AGENT], [10, 10, 10, 10, DSE],...</td>\n      <td>The woman|</td>\n      <td>complaining|</td>\n      <td>severe joint pains|</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>`` Since our technical equipment is far from p...</td>\n      <td>[[22, 22, 2, 4, TARGET], [22, 22, 10, 10, TARG...</td>\n      <td>Nazarov|</td>\n      <td>said|</td>\n      <td>our technical equipment|we|</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2444</th>\n      <td>Benjamin Franklin Federal Savings &amp; Loan Assoc...</td>\n      <td>[[9, 9, 8, 8, AGENT], [9, 9, 9, 9, DSE]]</td>\n      <td>it|</td>\n      <td>plans|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2445</th>\n      <td>thrift said the restructuring should help it m...</td>\n      <td>[[1, 1, 1, 1, DSE], [1, 1, 2, 3, TARGET]]</td>\n      <td>|</td>\n      <td>said|</td>\n      <td>the restructuring|</td>\n    </tr>\n    <tr>\n      <th>2446</th>\n      <td>Details of the restructuring wo n't be made fi...</td>\n      <td>[[11, 11, 10, 10, AGENT], [11, 11, 11, 11, DSE]]</td>\n      <td>regulators|</td>\n      <td>approve|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>Jay Stevens , an analyst with Dean Witter Reyn...</td>\n      <td>[[12, 12, 11, 11, AGENT], [12, 12, 12, 12, DSE]]</td>\n      <td>he|</td>\n      <td>expected|</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>2448</th>\n      <td>company to earn 35 cents a share for the quart...</td>\n      <td>[[11, 11, 11, 11, DSE], [11, 11, 12, 16, TARGET]]</td>\n      <td>|</td>\n      <td>said|</td>\n      <td>the firm 's weaker profit|</td>\n    </tr>\n  </tbody>\n</table>\n<p>2449 rows Ã— 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### getting evaluation data into df and dividing each of {agent, target, dse} elements","metadata":{}},{"cell_type":"code","source":"dev_df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.dev0.conll.json\")\n\nfor i in range(len(dev_df)):\n    agent, dse, target = organize_data(dev_df['orl'][i], dev_df['sep_sent'][i])\n    dev_df.loc[i, 'agent'] = agent\n    dev_df.loc[i, 'dse'] = dse\n    dev_df.loc[i, 'target'] = target","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:16:47.841895Z","iopub.execute_input":"2024-02-29T07:16:47.842599Z","iopub.status.idle":"2024-02-29T07:16:48.190952Z","shell.execute_reply.started":"2024-02-29T07:16:47.842549Z","shell.execute_reply":"2024-02-29T07:16:48.19013Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def pipeDivider(pipedString):\n    listOfItems = []\n    listOfItems = pipedString.split('|')[:-1]\n    return listOfItems","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:16:50.544647Z","iopub.execute_input":"2024-02-29T07:16:50.545343Z","iopub.status.idle":"2024-02-29T07:16:50.550316Z","shell.execute_reply.started":"2024-02-29T07:16:50.545309Z","shell.execute_reply":"2024-02-29T07:16:50.549349Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# it is here to iterate over every single dse -inner loop- of every sentence of the dataset -outer loop-\n# (very inefficient, i know. i havn't figured out what to do instead yet)\ntrain_df = pd.DataFrame(columns=['target_prompt', 'agent_prompt', 'target', 'agent'])\n\nfor i in range(len(df)):\n    dse_list = []\n    dse_list = pipeDivider(str(df.iloc[i]['dse']))\n    target_list = pipeDivider(str(df.iloc[i]['target']))\n    agent_list = pipeDivider(str(df.iloc[i]['agent']))\n    for j in range(len(dse_list)):\n        last_row = int(len(train_df))+1\n        train_df.loc[last_row, 'target_prompt'] = f\"Sentence is: {df.iloc[i]['sentence']} Find target for this dse: {dse_list[j]}\"\n        train_df.loc[last_row, 'agent_prompt'] = f\"Sentence is: {df.iloc[i]['sentence']} Find agent for this dse: {dse_list[j]}\"\n        train_df.loc[last_row, 'target'] = target_list[j]\n        train_df.loc[last_row, 'agent'] = agent_list[j]","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:16:54.302323Z","iopub.execute_input":"2024-02-29T07:16:54.302722Z","iopub.status.idle":"2024-02-29T07:16:57.416964Z","shell.execute_reply.started":"2024-02-29T07:16:54.302694Z","shell.execute_reply":"2024-02-29T07:16:57.416138Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# bug to fix, \ndef create_prompt(input_df):\n    for i in range(len(input_df)):\n        output_df = pd.DataFrame()\n        dse_list = []\n        dse_list = pipeDivider(str(input_df.iloc[i]['dse']))\n        target_list = pipeDivider(str(input_df.iloc[i]['target']))\n        agent_list = pipeDivider(str(input_df.iloc[i]['agent']))\n        for j in range(len(dse_list)):\n            last_row = int(len(output_df))+1\n            output_df.loc[last_row, 'target_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find target for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'agent_prompt'] = f\"Sentence is: {input_df.iloc[i]['sentence']} Find agent for this dse: {dse_list[j]}\"\n            output_df.loc[last_row, 'target'] = target_list[j]\n            output_df.loc[last_row, 'agent'] = agent_list[j]\n    return output_df\n\ncreate_prompt(df).head()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:29:56.716558Z","iopub.execute_input":"2024-02-29T07:29:56.717402Z","iopub.status.idle":"2024-02-29T07:30:03.089046Z","shell.execute_reply.started":"2024-02-29T07:29:56.717365Z","shell.execute_reply":"2024-02-29T07:30:03.087573Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4261\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4261\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4263\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'target_prompt'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mLossySetitemError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5285\u001b[0m, in \u001b[0;36mIndex._validate_fill_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp_can_hold_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5286\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LossySetitemError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5287\u001b[0m     \u001b[38;5;66;03m# re-raise as TypeError for consistency\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1802\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[0;34m(dtype, element)\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m element\n\u001b[0;32m-> 1802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LossySetitemError\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mLossySetitemError\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6927\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6926\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6927\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_fill_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   6929\u001b[0m     \u001b[38;5;66;03m# e.g. trying to insert an integer into a DatetimeIndex\u001b[39;00m\n\u001b[1;32m   6930\u001b[0m     \u001b[38;5;66;03m#  We cannot keep the same dtype, so cast to the (often object)\u001b[39;00m\n\u001b[1;32m   6931\u001b[0m     \u001b[38;5;66;03m#  minimal shared dtype before doing the insert.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5288\u001b[0m, in \u001b[0;36mIndex._validate_fill_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5286\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m LossySetitemError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5287\u001b[0m         \u001b[38;5;66;03m# re-raise as TypeError for consistency\u001b[39;00m\n\u001b[0;32m-> 5288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   5289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m can_hold_element(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, value):\n","\u001b[0;31mTypeError\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m             output_df\u001b[38;5;241m.\u001b[39mloc[last_row, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m agent_list[j]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_df\n\u001b[0;32m---> 17\u001b[0m \u001b[43mcreate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n","Cell \u001b[0;32mIn[20], line 11\u001b[0m, in \u001b[0;36mcreate_prompt\u001b[0;34m(input_df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dse_list)):\n\u001b[1;32m     10\u001b[0m     last_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_df))\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[43moutput_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_prompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Find target for this dse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdse_list[j]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     output_df\u001b[38;5;241m.\u001b[39mloc[last_row, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Find agent for this dse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdse_list[j]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     output_df\u001b[38;5;241m.\u001b[39mloc[last_row, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m target_list[j]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 885\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1844\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key] \u001b[38;5;241m=\u001b[39m empty_value\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     \u001b[38;5;66;03m# FIXME: GH#42099#issuecomment-864326014\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m infer_fill_value(value)\n\u001b[1;32m   1846\u001b[0m new_indexer \u001b[38;5;241m=\u001b[39m convert_from_missing_indexer_tuple(\n\u001b[1;32m   1847\u001b[0m     indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39maxes\n\u001b[1;32m   1848\u001b[0m )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(new_indexer, value, name)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4314\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4311\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   4312\u001b[0m             refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4264\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value, refs)\u001b[0m\n\u001b[1;32m   4261\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   4263\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 4264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:1323\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03mInsert item at selected position.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03mrefs : The reference tracking object of the value to set.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;66;03m# insert to the axis; this could possibly raise a TypeError\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m new_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1326\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/range.py:900\u001b[0m, in \u001b[0;36mRangeIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m    897\u001b[0m         new_rng \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, step)\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(new_rng, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m--> 900\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6933\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   6929\u001b[0m     \u001b[38;5;66;03m# e.g. trying to insert an integer into a DatetimeIndex\u001b[39;00m\n\u001b[1;32m   6930\u001b[0m     \u001b[38;5;66;03m#  We cannot keep the same dtype, so cast to the (often object)\u001b[39;00m\n\u001b[1;32m   6931\u001b[0m     \u001b[38;5;66;03m#  minimal shared dtype before doing the insert.\u001b[39;00m\n\u001b[1;32m   6932\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_common_type_compat(item)\n\u001b[0;32m-> 6933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minsert(loc, item)\n\u001b[1;32m   6935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   6936\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[1;32m   6937\u001b[0m ):\n\u001b[1;32m   6938\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[1;32m   6939\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[1;32m   6940\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[1;32m   6941\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:1089\u001b[0m, in \u001b[0;36mIndex.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_sequence(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# GH#13149 specifically use astype_array instead of astype\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# pass copy=False because any copying will be done in the astype above\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m result \u001b[38;5;241m=\u001b[39m Index(new_values, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39mnew_values\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:100\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     95\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missubdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloating\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/numerictypes.py:356\u001b[0m, in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Determine if the first argument is a subclass of the second argument.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(obj2sctype(arg1), obj2sctype(arg2))\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missubdtype\u001b[39m(arg1, arg2):\n\u001b[1;32m    358\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    Returns True if first argument is a typecode lower/equal in type hierarchy.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issubclass_(arg1, generic):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"dev_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T07:21:40.150615Z","iopub.execute_input":"2024-02-29T07:21:40.151342Z","iopub.status.idle":"2024-02-29T07:21:40.176343Z","shell.execute_reply.started":"2024-02-29T07:21:40.151308Z","shell.execute_reply":"2024-02-29T07:21:40.175287Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                            sentence  \\\n0  The owner though that the animal was suffering...   \n1  The owner put down the animal , although the v...   \n2  GATUNA , Rwanda , July 6 -LRB- AFP -RRB- - Pre...   \n3  The formerly close allies fell out in 1999 , t...   \n4  In March , Uganda declared Rwanda a hostile na...   \n\n                                                 orl  \\\n0  [[2, 2, 0, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...   \n1  [[10, 11, 8, 9, AGENT], [10, 11, 10, 11, DSE],...   \n2  [[30, 32, 30, 32, DSE], [30, 32, 33, 35, TARGET]]   \n3  [[4, 5, 0, 3, AGENT], [4, 5, 4, 5, DSE], [4, 5...   \n4  [[4, 4, 3, 3, AGENT], [4, 4, 4, 4, DSE], [4, 4...   \n\n                                            sep_sent  \\\n0  [The, owner, though, that, the, animal, was, s...   \n1  [The, owner, put, down, the, animal, ,, althou...   \n2  [GATUNA, ,, Rwanda, ,, July, 6, -LRB-, AFP, -R...   \n3  [The, formerly, close, allies, fell, out, in, ...   \n4  [In, March, ,, Uganda, declared, Rwanda, a, ho...   \n\n                                               agent  \\\n0                                         The owner|   \n1                                           the vet|   \n2                                                  |   \n3  The formerly close allies|The formerly close a...   \n4                                        Uganda| | |   \n\n                          dse  \\\n0                     though|   \n1              had forbidden|   \n2   soured relations between|   \n3  fell out|mounting rivalry|   \n4   declared|alleged|support|   \n\n                                              target  \n0                                        the animal|  \n1                                      him to do so|  \n2                      their neighbouring countries|  \n3                                            each| |  \n4  Rwanda|Kigali|a rival to Museveni in a preside...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>orl</th>\n      <th>sep_sent</th>\n      <th>agent</th>\n      <th>dse</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The owner though that the animal was suffering...</td>\n      <td>[[2, 2, 0, 1, AGENT], [2, 2, 2, 2, DSE], [2, 2...</td>\n      <td>[The, owner, though, that, the, animal, was, s...</td>\n      <td>The owner|</td>\n      <td>though|</td>\n      <td>the animal|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The owner put down the animal , although the v...</td>\n      <td>[[10, 11, 8, 9, AGENT], [10, 11, 10, 11, DSE],...</td>\n      <td>[The, owner, put, down, the, animal, ,, althou...</td>\n      <td>the vet|</td>\n      <td>had forbidden|</td>\n      <td>him to do so|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GATUNA , Rwanda , July 6 -LRB- AFP -RRB- - Pre...</td>\n      <td>[[30, 32, 30, 32, DSE], [30, 32, 33, 35, TARGET]]</td>\n      <td>[GATUNA, ,, Rwanda, ,, July, 6, -LRB-, AFP, -R...</td>\n      <td>|</td>\n      <td>soured relations between|</td>\n      <td>their neighbouring countries|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The formerly close allies fell out in 1999 , t...</td>\n      <td>[[4, 5, 0, 3, AGENT], [4, 5, 4, 5, DSE], [4, 5...</td>\n      <td>[The, formerly, close, allies, fell, out, in, ...</td>\n      <td>The formerly close allies|The formerly close a...</td>\n      <td>fell out|mounting rivalry|</td>\n      <td>each| |</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>In March , Uganda declared Rwanda a hostile na...</td>\n      <td>[[4, 4, 3, 3, AGENT], [4, 4, 4, 4, DSE], [4, 4...</td>\n      <td>[In, March, ,, Uganda, declared, Rwanda, a, ho...</td>\n      <td>Uganda| | |</td>\n      <td>declared|alleged|support|</td>\n      <td>Rwanda|Kigali|a rival to Museveni in a preside...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data['sentence'][idx]\n        agent = self.data['agent'][idx]\n        dse = self.data['dse'][idx]\n        target = self.data['target'][idx]\n        text_encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        #agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #dse\n        dse_encoding = self.tokenizer(dse, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        #target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            #text\n            'input_ids': text_encoding['input_ids'].squeeze(),\n            'attention_mask': text_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #dse\n            'dse_id': dse_encoding['input_ids'].squeeze(),\n            'dse_mask': dse_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a data loader\ntrain_dataset = CustomDataset(df[:2500], tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\ntrain_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataset = CustomDataset(dev_df, tokenizer, max_length4text=max_input_length, max_length4label=max_label_length)\nval_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleaner(str_item):\n    final_string_list = []\n    string_list = str_item.split('|')\n    for i in string_list:\n        j = i.replace(' ', '')\n        if len(j) > 0:\n            # data cleaning\n            final_string_list.append(j)\n            \n    return final_string_list\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaner(\"a|b|  |\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_calculator(pred_list, actual_list):\n    cleaned_pred, cleaned_actual = [], []\n    matched = 0\n    for i in range(len(pred_list)):\n        pred_items = cleaner(pred_list[i])\n        actual_items = cleaner(actual_list[i])\n        # function:\n        for j in range(len(actual_items)):\n            print(actual_items[j])\n            if actual_items[j] in pred_items:\n                matched += 1\n                print(f'** actual ** \\n')\n        cleaned_pred.extend(pred_items)\n        cleaned_actual.extend(actual_items)\n    \n    prediction_len = len(cleaned_pred)\n    actual_len = len(cleaned_actual)\n    print(f'matched: {matched}, prediction_len:{prediction_len}, actual_len:{actual_len} \\n')\n    try:\n        precision = (matched / prediction_len)\n        recall = (matched / actual_len)\n        f1 = (2 * (precision * recall)) / (precision + recall)\n    except:\n        f1 = 0\n    return f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, dataloader):\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        true_counted, prediction_counted, actual_counted = 0,0,0\n        matched, prediction_len, actual_len = 0,0,0\n        actual_list, prediction_list, f1 = [], [], []\n        for batch_idx, batch in enumerate(dataloader):\n            # Move data to the specified device\n            # batch = {key: value.to('cuda') for key, value in batch.items()}\n\n            # Forward pass\n            ids = batch['input_ids']\n            mask = batch['attention_mask']\n            target_id = batch['dse_id']\n            \n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in target_id]\n            \n            output = generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=64, \n              )\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output]\n            \n            actual_list.extend(actuals)\n            prediction_list.extend(preds)\n    return f1_calculator(prediction_list, actual_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCH):\n    losses = []\n    print(f'epoch: {epoch} \\n')\n    for batch in train_data_loader:\n        inputs = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        dse_id = batch['dse_id']\n        dse_mask = batch['dse_mask']\n\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask, labels=dse_id)\n        loss = outputs.loss\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    f1 = evaluate_model(model, val_data_loader)\n    print(f'loss: {np.mean(losses)}, f1 validation:{f1} \\n end of epoch{epoch}. \\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCH):\n    print(f'epoch: {epoch} \\n')\n    accuracy = evaluate_model(model, val_data_loader)\n    print(f'accuracy: {accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = \"find expression of the sentence: The Palestinians want nothing from Washington but to understand their cause and stand beside right and justice .\"\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}