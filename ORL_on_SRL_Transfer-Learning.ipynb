{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6950004,"sourceType":"datasetVersion","datasetId":3991553},{"sourceId":10404472,"sourceType":"datasetVersion","datasetId":5836801},{"sourceId":249349,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":209145,"modelId":230838}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2078.052058,"end_time":"2024-09-26T12:00:40.153852","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-26T11:26:02.101794","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"provenance":[],"include_colab_link":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/houman-nr/vigilant-umbrella/blob/main/ORL_on_SRL_Transfer-Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"! pip install transformers\n! pip install torch","metadata":{"papermill":{"duration":29.189487,"end_time":"2024-09-26T11:26:35.267247","exception":false,"start_time":"2024-09-26T11:26:06.077760","status":"completed"},"tags":[],"trusted":true,"id":"T6ubBx04v7yz","outputId":"78d9fb80-3e5e-4898-da28-38974f746ac6","execution":{"iopub.status.busy":"2025-02-27T16:21:54.086763Z","iopub.execute_input":"2025-02-27T16:21:54.087220Z","iopub.status.idle":"2025-02-27T16:22:02.995537Z","shell.execute_reply.started":"2025-02-27T16:21:54.087185Z","shell.execute_reply":"2025-02-27T16:22:02.994664Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### importing libraries","metadata":{"papermill":{"duration":0.014528,"end_time":"2024-09-26T11:26:35.296420","exception":false,"start_time":"2024-09-26T11:26:35.281892","status":"completed"},"tags":[],"id":"IO6o5JO_v7y5"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport json\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom itertools import zip_longest","metadata":{"papermill":{"duration":12.728315,"end_time":"2024-09-26T11:26:48.042165","exception":false,"start_time":"2024-09-26T11:26:35.313850","status":"completed"},"tags":[],"trusted":true,"id":"y9Do2PfVv7y8","execution":{"iopub.status.busy":"2025-02-27T16:22:02.996696Z","iopub.execute_input":"2025-02-27T16:22:02.996968Z","iopub.status.idle":"2025-02-27T16:22:32.449004Z","shell.execute_reply.started":"2025-02-27T16:22:02.996936Z","shell.execute_reply":"2025-02-27T16:22:32.448254Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### defining general variables","metadata":{"papermill":{"duration":0.011678,"end_time":"2024-09-26T11:26:48.066273","exception":false,"start_time":"2024-09-26T11:26:48.054595","status":"completed"},"tags":[],"id":"W9oVXuPrv7y_"}},{"cell_type":"code","source":"#defining global valriables throughout the whole notebook\nEPOCH = 32\nBATCH_SIZE = 64\nMAX_INPUT_LENGTH = 65\nMAX_LABEL_LENGTH = 8\nMODEL_LINK = \"google/flan-t5-small\"\nFOLD_NUMBER = 3\nSEED = 0\nsrl_data_link = '/kaggle/input/srl-w-cluster-number103k/SRL_Dataset_With_60_Clusters-Similarity.csv'\nstate_dictionary = '/kaggle/input/t5-small_fine-tuned_mpqa/pytorch/0/2/output (1).pt'","metadata":{"papermill":{"duration":0.019504,"end_time":"2024-09-26T11:26:48.097053","exception":false,"start_time":"2024-09-26T11:26:48.077549","status":"completed"},"tags":[],"trusted":true,"id":"-ZUy1eJ8v7zB","execution":{"iopub.status.busy":"2025-02-27T16:22:32.450294Z","iopub.execute_input":"2025-02-27T16:22:32.450919Z","iopub.status.idle":"2025-02-27T16:22:32.455996Z","shell.execute_reply.started":"2025-02-27T16:22:32.450892Z","shell.execute_reply":"2025-02-27T16:22:32.454798Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def set_seed():\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"trusted":true,"id":"TuFvwLngv7zD","execution":{"iopub.status.busy":"2025-02-27T16:22:32.457728Z","iopub.execute_input":"2025-02-27T16:22:32.458142Z","iopub.status.idle":"2025-02-27T16:22:32.579335Z","shell.execute_reply.started":"2025-02-27T16:22:32.458099Z","shell.execute_reply":"2025-02-27T16:22:32.578320Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"set_seed()\ntokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')","metadata":{"papermill":{"duration":8.674111,"end_time":"2024-09-26T11:26:56.782868","exception":false,"start_time":"2024-09-26T11:26:48.108757","status":"completed"},"tags":[],"trusted":true,"id":"gkASgD5hv7zF","outputId":"cbad011e-a725-44e5-855e-2e02cc2d640d","execution":{"iopub.status.busy":"2025-02-27T16:22:32.580735Z","iopub.execute_input":"2025-02-27T16:22:32.581156Z","iopub.status.idle":"2025-02-27T16:22:36.330904Z","shell.execute_reply.started":"2025-02-27T16:22:32.581118Z","shell.execute_reply":"2025-02-27T16:22:36.330105Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f92f750a73b44a5b900b87bd590cfda2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb29cb76e1144a029513f23db7f771b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fd2913bfed444a48326aee4fe4f9e37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60a2bce8d14458f9c991d40edd5256c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"207567fb812c44c8956ce0c3d5eb7ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf05017816184df583325934e9bd8e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1ef497601414e0185d6b5792ae93d14"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### functions created for reading(get_data) and organize the files (organize_data)","metadata":{"papermill":{"duration":0.012779,"end_time":"2024-09-26T11:26:56.808902","exception":false,"start_time":"2024-09-26T11:26:56.796123","status":"completed"},"tags":[],"id":"UW4vbMnEv7zG"}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n# Define a custom dataset\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length4text = max_length4text\n        self.max_length4label = max_length4label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        agent_prompt = self.data['agent_prompt'][idx]\n        target_prompt = self.data['target_prompt'][idx]\n        agent = self.data['agent'][idx]\n        target = self.data['target'][idx]\n        # tokenizing agent prompt\n        agent_prompt_encoding = self.tokenizer(agent_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing target prompt\n        target_prompt_encoding = self.tokenizer(target_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n        # tokenizing agent\n        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        # tokenizing target\n        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n        return {\n            # agent prompt\n            'agent_input_id': agent_prompt_encoding['input_ids'].squeeze(),\n            'agent_attention_mask': agent_prompt_encoding['attention_mask'].squeeze(),\n            # target prompt\n            'target_input_id': target_prompt_encoding['input_ids'].squeeze(),\n            'target_attention_mask': target_prompt_encoding['attention_mask'].squeeze(),\n            #agent\n            'agent_id': agent_encoding['input_ids'].squeeze(),\n            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n            #target\n            'target_id': target_encoding['input_ids'].squeeze(),\n            'target_mask': target_encoding['attention_mask'].squeeze()\n        }","metadata":{"papermill":{"duration":0.029669,"end_time":"2024-09-26T11:27:08.487210","exception":false,"start_time":"2024-09-26T11:27:08.457541","status":"completed"},"tags":[],"trusted":true,"id":"5dZrno25v7zV","execution":{"iopub.status.busy":"2025-02-27T16:22:36.331835Z","iopub.execute_input":"2025-02-27T16:22:36.332175Z","iopub.status.idle":"2025-02-27T16:22:36.340492Z","shell.execute_reply.started":"2025-02-27T16:22:36.332135Z","shell.execute_reply":"2025-02-27T16:22:36.339320Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the loss function and optimizer\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)","metadata":{"papermill":{"duration":0.828199,"end_time":"2024-09-26T11:27:09.329609","exception":false,"start_time":"2024-09-26T11:27:08.501410","status":"completed"},"tags":[],"trusted":true,"id":"8LGbOyBjv7zW","execution":{"iopub.status.busy":"2025-02-27T16:22:36.341440Z","iopub.execute_input":"2025-02-27T16:22:36.341852Z","iopub.status.idle":"2025-02-27T16:22:36.367635Z","shell.execute_reply.started":"2025-02-27T16:22:36.341817Z","shell.execute_reply":"2025-02-27T16:22:36.366905Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def f1_calculator(split_pred_list, split_actual_list):\n    matched, percision, recall, f1 = 0, 0, 0, 0\n    predicted_len, actual_len      = 0, 0\n\n    for actual_sublist, prediction_sublist in zip(split_pred_list, split_actual_list):\n        predicted_len += len(prediction_sublist)\n        for i in actual_sublist:\n            actual_len += 1\n            if i in prediction_sublist:\n                matched += 1\n\n    print(f\"matched: {matched}, predicted_len: {predicted_len}, actual_len: {actual_len}\")\n    try:\n        precision = matched / predicted_len\n        recall = matched / actual_len\n        f1 = 2 * (precision * recall) / (precision + recall)\n    except ZeroDivisionError:\n        f1 = 0\n\n    return f1","metadata":{"papermill":{"duration":0.0255,"end_time":"2024-09-26T11:27:09.370039","exception":false,"start_time":"2024-09-26T11:27:09.344539","status":"completed"},"tags":[],"trusted":true,"id":"C8ge_Vsnv7zX","execution":{"iopub.status.busy":"2025-02-27T16:22:36.370146Z","iopub.execute_input":"2025-02-27T16:22:36.370392Z","iopub.status.idle":"2025-02-27T16:22:36.385764Z","shell.execute_reply.started":"2025-02-27T16:22:36.370363Z","shell.execute_reply":"2025-02-27T16:22:36.385045Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def clear_data(text_list):\n    list_of_items_in_text = []\n    for single_list in text_list:\n        for i in single_list.split('|'):\n            i = i.lower().replace(\" \", \"\")  # Convert to lowercase and remove extra whitespace\n            if i:  # Check if `i` is not empty after stripping\n                list_of_items_in_text.append(i)\n    return list_of_items_in_text","metadata":{"trusted":true,"id":"YKnwFRhVv7zY","execution":{"iopub.status.busy":"2025-02-27T16:22:36.387218Z","iopub.execute_input":"2025-02-27T16:22:36.387450Z","iopub.status.idle":"2025-02-27T16:22:36.410868Z","shell.execute_reply.started":"2025-02-27T16:22:36.387430Z","shell.execute_reply":"2025-02-27T16:22:36.410092Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def evaluate_model(model, dataloader, prompt_type):\n    if prompt_type == 'target':\n        id_type = 'target_input_id'\n        attention_type = 'target_attention_mask'\n        output_type = 'target_id'\n    elif prompt_type == 'agent':\n        id_type = 'agent_input_id'\n        attention_type = 'agent_attention_mask'\n        output_type = 'agent_id'\n\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        actual_list, prediction_list = [], []\n        for batch_idx, batch in enumerate(dataloader):\n\n            # Forward pass\n            ids = batch[id_type]\n            mask = batch[attention_type]\n            output_id = batch[output_type]\n\n            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output_id]\n\n            generated_output = model.generate(\n              input_ids = ids,\n              attention_mask = mask,\n              max_length=64,\n              )\n            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_output]\n\n            actual_list.append(clear_data(actuals))\n            prediction_list.append(clear_data(preds))\n\n    return f1_calculator(prediction_list, actual_list)","metadata":{"papermill":{"duration":0.030366,"end_time":"2024-09-26T11:27:09.415309","exception":false,"start_time":"2024-09-26T11:27:09.384943","status":"completed"},"tags":[],"trusted":true,"id":"5B7YdpTSv7zZ","execution":{"iopub.status.busy":"2025-02-27T16:22:36.411872Z","iopub.execute_input":"2025-02-27T16:22:36.412230Z","iopub.status.idle":"2025-02-27T16:22:36.429091Z","shell.execute_reply.started":"2025-02-27T16:22:36.412197Z","shell.execute_reply":"2025-02-27T16:22:36.428172Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"f1_scores_target, f1_scores_agent = [], []\n#           data_loader:train,v_data_loader:validation\ndef train_data(data_loader, v_data_loader):\n    data_list = []\n    model.train()\n    for epoch in range(EPOCH):\n        losses = []\n        for batch in data_loader:\n\n            agent_input = batch['agent_input_id']\n            agent_attention_mask = batch['agent_attention_mask']\n\n            target_input = batch['target_input_id']\n            target_attention_mask = batch['target_attention_mask']\n\n            agent_id = batch['agent_id']\n            agent_mask = batch['agent_mask']\n\n            target_id = batch['target_id']\n            target_mask = batch['target_mask']\n\n            optimizer.zero_grad()\n\n            agent_output = model(agent_input, attention_mask=agent_attention_mask, labels=agent_id)\n            target_output = model(target_input, attention_mask=target_attention_mask, labels=target_id)\n\n            agent_loss = agent_output.loss\n            target_loss = target_output.loss\n            losses.append(agent_loss.item())\n            losses.append(target_loss.item())\n\n            agent_loss.backward()\n            target_loss.backward()\n            optimizer.step()\n\n\n        f1_4_target = evaluate_model(model, v_data_loader, 'target')\n        f1_4_agent = evaluate_model(model, v_data_loader, 'agent')\n\n        f1_scores_target.append(f1_4_target)\n        f1_scores_agent.append(f1_4_agent)\n\n        # report the results of training function.\n        print(f'loss: {np.mean(losses)}, f1 for target:{f1_4_target}, f1 for agent:{f1_4_agent} \\n end of epoch{epoch}. \\n')","metadata":{"papermill":{"duration":0.027986,"end_time":"2024-09-26T11:27:09.457947","exception":false,"start_time":"2024-09-26T11:27:09.429961","status":"completed"},"tags":[],"trusted":true,"id":"GDLmQo94v7za","execution":{"iopub.status.busy":"2025-02-27T16:22:36.430004Z","iopub.execute_input":"2025-02-27T16:22:36.430237Z","iopub.status.idle":"2025-02-27T16:22:36.451810Z","shell.execute_reply.started":"2025-02-27T16:22:36.430217Z","shell.execute_reply":"2025-02-27T16:22:36.451151Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Training t5-small on SRL (srl dev and test too)\n# first part of 2 transfer learning sections","metadata":{}},{"cell_type":"markdown","source":"### .\n### .\n### .\n### .\n## chosing randomly out of SRL_without_anchors for calculating the results\n### .\n### .\n### .\n### .","metadata":{"papermill":{"duration":0.014835,"end_time":"2024-09-26T11:27:09.517168","exception":false,"start_time":"2024-09-26T11:27:09.502333","status":"completed"},"tags":[],"id":"cw7ckxXGv7zb"}},{"cell_type":"code","source":"# srl = pd.read_csv(srl_data_link)\n# agents, targets, verbs, sentences, cluster_number = [], [], [], [], []\n# for i in range(len(srl)):\n\n#     #single line of data is selected from df\n#     line = srl.iloc[i]\n\n#     #check for both ARGS,\n#     #if both are empty skips that line.\n#     #if either one of the args is filled-\n#     #-process continues.\n#     if line['ARG0'] or line['ARG1']:\n#         if line['ARG0']:\n#             agents.append(line['ARG0'])\n#         else:\n#             agents.append(\"\")\n#         if line['ARG1']:\n#             targets.append(line['ARG1'])\n#         else:\n#             targets.append(\"\")\n#         sentences.append(line['SENTENCE'])\n#         verbs.append(line['PREDICATES'])\n#         cluster_number.append(line['Cluster_Number'])\n\n# srl_df = pd.DataFrame({'sentences': sentences, 'verbs': verbs, 'agents': agents, 'targets': targets, 'cluster_no':cluster_number}, dtype='object').fillna('')\n# srl_df","metadata":{"papermill":{"duration":1.156441,"end_time":"2024-09-26T11:27:10.689172","exception":false,"start_time":"2024-09-26T11:27:09.532731","status":"completed"},"tags":[],"trusted":true,"id":"aVu6OFUzv7zb","outputId":"1c08e090-6b37-4eb7-be9b-06e092d039c5","execution":{"iopub.status.busy":"2025-02-27T16:22:36.452671Z","iopub.execute_input":"2025-02-27T16:22:36.452965Z","iopub.status.idle":"2025-02-27T16:22:36.475191Z","shell.execute_reply.started":"2025-02-27T16:22:36.452918Z","shell.execute_reply":"2025-02-27T16:22:36.474213Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# agent_prompts, agents, target_prompts, targets, cluster_no = [], [], [], [], []\n# for i in range(len(srl_df)):\n#     line = srl_df.iloc[i]\n#     agent_prompts.append(f\"sentence is: {line['sentences']} this is verb: {line['verbs']} find agent for this veerb in the sentence\")\n#     agents.append(line['agents'])\n#     target_prompts.append(f\"sentence is: {line['sentences']} this is verb: {line['verbs']} find target for this verb in the sentence\")\n#     targets.append(line['targets'])\n#     cluster_no.append(line['cluster_no'])\n#     # (f\"sentence is: \\{{input_df['sentence'][i]}} this is DSE: {input_df['dse'][i]}. find target for DSE in the sentence?\")\n# srl_df = []\n# srl_df = pd.DataFrame({'agent_prompt': agent_prompts, 'agent': agents, 'target_prompt': target_prompts, 'target': targets, 'cluster_no':cluster_no})\n# srl_df","metadata":{"papermill":{"duration":0.730236,"end_time":"2024-09-26T11:27:11.435423","exception":false,"start_time":"2024-09-26T11:27:10.705187","status":"completed"},"tags":[],"trusted":true,"id":"uZaKCAFsv7zd","outputId":"51f5344b-752c-4f1b-9b62-ae1be734f3cc","execution":{"iopub.status.busy":"2025-02-27T16:22:36.476224Z","iopub.execute_input":"2025-02-27T16:22:36.476459Z","iopub.status.idle":"2025-02-27T16:22:36.497565Z","shell.execute_reply.started":"2025-02-27T16:22:36.476429Z","shell.execute_reply":"2025-02-27T16:22:36.496989Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"#### randomly selecting number of this dataframe to be fed into the model\n\n##### 4000 lines of data is the limit of notebook with GPU T4*2 memory limit\n##### 60 clusters to chose from, Results in almost 66.6... from each cluster","metadata":{"papermill":{"duration":0.015757,"end_time":"2024-09-26T11:27:11.467508","exception":false,"start_time":"2024-09-26T11:27:11.451751","status":"completed"},"tags":[],"id":"CXNToLi-v7zd"}},{"cell_type":"code","source":"# def random_sample_df(df, num_rows, SEED=None):\n#     # Check if num_rows is larger than the available number of rows in the DataFrame\n#     if num_rows > len(df):\n#         raise ValueError(f\"Requested {num_rows} rows, but the DataFrame only contains {len(df)} rows.\")\n\n#     # Sample the DataFrame and return the result\n#     sampled_df = df.sample(n=num_rows, random_state=SEED)\n#     return sampled_df\n\n# def random_sample_from_all_clusters(df, num_rows_per_cluster, cluster_column, SEED=None):\n#     # Check if the cluster_column exists in the DataFrame\n#     if cluster_column not in df.columns:\n#         raise ValueError(f\"Column '{cluster_column}' not found in DataFrame.\")\n\n#     # Create an empty list to hold the sampled data for each cluster\n#     sampled_dfs = []\n\n#     # Group the DataFrame by the cluster column\n#     grouped = df.groupby(cluster_column)\n\n#     # Iterate over each cluster and sample rows\n#     for cluster, group in grouped:\n#         # Check if the group has enough rows to sample\n#         if len(group) < num_rows_per_cluster:\n#             raise ValueError(f\"Cluster '{cluster}' has only {len(group)} rows, but {num_rows_per_cluster} were requested.\")\n\n#         # Sample the rows from the current cluster\n#         sampled_group = group.sample(n=num_rows_per_cluster, random_state=SEED)\n#         sampled_dfs.append(sampled_group)\n\n#     # Concatenate the sampled DataFrames for each cluster\n#     sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n\n#     return sampled_df\n\n\n# srl_nk = random_sample_from_all_clusters(srl_df, 170, 'cluster_no', SEED)\n# srl_test_df = srl_nk[:1500]\n# srl_dev_df = srl_nk[1501:3992]\n# srl_train_df = srl_nk[3993:]\n# srl_train_df.reset_index(inplace=True, drop=True)\n# srl_test_df.reset_index(inplace=True, drop=True)\n# srl_dev_df.reset_index(inplace=True, drop=True)\n# srl_train_df","metadata":{"papermill":{"duration":0.038497,"end_time":"2024-09-26T11:27:11.521955","exception":false,"start_time":"2024-09-26T11:27:11.483458","status":"completed"},"tags":[],"trusted":true,"id":"Wm6FRhYNv7ze","outputId":"1e977f9b-4b13-4d40-f2fb-ff1aa479dcd7","execution":{"iopub.status.busy":"2025-02-27T16:22:36.498775Z","iopub.execute_input":"2025-02-27T16:22:36.499071Z","iopub.status.idle":"2025-02-27T16:22:36.515447Z","shell.execute_reply.started":"2025-02-27T16:22:36.499042Z","shell.execute_reply":"2025-02-27T16:22:36.514788Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# # srl dataset for train\n# # orl dev set for validation\n# # orl test set for testing\n\n\n# # Create a data loader for TRAIN dataframe\n# train_dataset = CustomDataset(srl_train_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n# train_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# # Create a data loader for EVALUATION dataframe\n# val_dataset = CustomDataset(srl_dev_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n# val_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# # Create a data loader for TEST dataframe\n# test_dataset = CustomDataset(srl_test_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n# test_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)\n","metadata":{"trusted":true,"id":"1nOBOzcav7zi","execution":{"iopub.status.busy":"2025-02-27T16:22:36.516258Z","iopub.execute_input":"2025-02-27T16:22:36.516476Z","iopub.status.idle":"2025-02-27T16:22:36.536231Z","shell.execute_reply.started":"2025-02-27T16:22:36.516448Z","shell.execute_reply":"2025-02-27T16:22:36.535584Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# train_data(train_data_loader, val_data_loader)","metadata":{"papermill":{"duration":1973.261252,"end_time":"2024-09-26T12:00:04.906971","exception":false,"start_time":"2024-09-26T11:27:11.645719","status":"completed"},"tags":[],"trusted":true,"id":"PhdMpbtqv7zj","outputId":"66638e85-4704-4fa6-fd70-2d4db34bb705","execution":{"iopub.status.busy":"2025-02-27T16:22:36.537086Z","iopub.execute_input":"2025-02-27T16:22:36.537365Z","iopub.status.idle":"2025-02-27T16:22:36.557671Z","shell.execute_reply.started":"2025-02-27T16:22:36.537337Z","shell.execute_reply":"2025-02-27T16:22:36.557077Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# # Plot F1 scores for target and agent\n# epochs = range(0, EPOCH)\n\n# plt.figure(figsize=(10, 6))\n# plt.plot(epochs, f1_scores_target, label='F1 Target', marker='o')\n# plt.plot(epochs, f1_scores_agent, label='F1 Agent', marker='o')\n\n# plt.xlabel('Epochs')\n# plt.ylabel('F1 Score')\n# plt.title('F1 Scores for Target and Agent over Epochs')\n# plt.legend()\n# plt.grid(True)\n# plt.show()","metadata":{"papermill":{"duration":0.462293,"end_time":"2024-09-26T12:00:05.387802","exception":false,"start_time":"2024-09-26T12:00:04.925509","status":"completed"},"tags":[],"trusted":true,"id":"ysDuCAN5v7zk","outputId":"9f151c68-24e0-4a7d-d0ab-67bef97564f7","execution":{"iopub.status.busy":"2025-02-27T16:22:36.558380Z","iopub.execute_input":"2025-02-27T16:22:36.558585Z","iopub.status.idle":"2025-02-27T16:22:36.573715Z","shell.execute_reply.started":"2025-02-27T16:22:36.558567Z","shell.execute_reply":"2025-02-27T16:22:36.573164Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# target_accuracy = evaluate_model(model, val_data_loader, 'target')\n# agent_accuracy = evaluate_model(model, val_data_loader, 'agent')\n# print(f'f1 Agent: {agent_accuracy}. f1 Target: {target_accuracy}\\n\\n----------------------')","metadata":{"papermill":{"duration":31.79925,"end_time":"2024-09-26T12:00:37.496787","exception":false,"start_time":"2024-09-26T12:00:05.697537","status":"completed"},"tags":[],"_kg_hide-output":true,"trusted":true,"id":"OJD-lhSTv7zl","outputId":"afd43c47-d0ab-44a8-fad1-1f3d3f288e1c","execution":{"iopub.status.busy":"2025-02-27T16:22:36.574455Z","iopub.execute_input":"2025-02-27T16:22:36.574746Z","iopub.status.idle":"2025-02-27T16:22:36.589291Z","shell.execute_reply.started":"2025-02-27T16:22:36.574679Z","shell.execute_reply":"2025-02-27T16:22:36.588436Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# torch.save(model.state_dict(), 'output.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:36.589949Z","iopub.execute_input":"2025-02-27T16:22:36.590159Z","iopub.status.idle":"2025-02-27T16:22:36.606448Z","shell.execute_reply.started":"2025-02-27T16:22:36.590141Z","shell.execute_reply":"2025-02-27T16:22:36.605877Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Feeding state dictionary of the previously trained model and fine-tuning model on ORL data.\n## ","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/t5-small_fine-tuned_mpqa/pytorch/0/2/output (1).pt'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:36.607167Z","iopub.execute_input":"2025-02-27T16:22:36.607434Z","iopub.status.idle":"2025-02-27T16:22:39.959252Z","shell.execute_reply.started":"2025-02-27T16:22:36.607408Z","shell.execute_reply":"2025-02-27T16:22:39.958535Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-20-8c7c6e68c4eb>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/t5-small_fine-tuned_mpqa/pytorch/0/2/output (1).pt'))\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# a funciton to read data off of a database link is here to help getting and organizing data into dataframes\ndef get_data(address):\n    lines = []\n    with open(address) as file:\n        for line in file:\n            x = json.loads(line)\n            lines.append(x)\n    sentences, orl, sep_sentences = [], [], []\n    for i in range(len(lines)):\n        sep_sentences.append(lines[i]['sentences'])\n        sentences.append(' '.join(lines[i]['sentences']))\n        orl.append(lines[i]['orl'])\n    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n    return dataframe\n\n# this function is to make a list of the said attribute for later iterations\ndef list_of(attributes, requested_atr):\n    requested_list = []\n    for sublist in attributes:\n        if sublist[-1] == requested_atr:\n            requested_list.append(sublist)\n    return requested_list\n\n# this function was made to find target(s)/agent(s) of a dse according to list of attributes\ndef organize_data(dataframe):\n    \n    target_column, agent_column, sentence_column, dse_column = [], [], [], []\n    \n    for i in range(len(dataframe)):\n        \n        attributes = dataframe['orl'][i]\n        sentence   = dataframe['sep_sent'][i]\n        target_list= list_of(attributes, 'TARGET')\n        agent_list = list_of(attributes, 'AGENT')\n        AGENT, DSE, TARGET = '', '', ''\n        \n        \n        for sublist in attributes:\n            if sublist[-1] == 'DSE':\n                dse_start = int(sublist[0])\n                dse_end = int(sublist[1] + 1)\n                DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n                \n                \n                # looking for the targets and agents of this dse that we have found\n                for sub_sublist in target_list:\n                    if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                        target_start = int(sub_sublist[2])\n                        target_end = int(sub_sublist[3] + 1)\n                        TARGET += ' '.join(sentence[target_start:target_end]) + ' |'\n                if not TARGET:\n                    TARGET += ' |'\n                \n                for sub_sublist in agent_list:\n                    if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n                        agent_start = int(sub_sublist[2])\n                        agent_end = int(sub_sublist[3] + 1)\n                        AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n                if not AGENT:\n                    AGENT += ' |'\n                # for every iteration of loop over attributes, if a dse is found, then we need to transfer it to new line of a dataframe\n                # for each one of the dse(s) i have to add them into a new array so then they can create the correct dataframe\n                target_column.append(TARGET)\n                agent_column.append(AGENT)\n                dse_column.append(DSE)\n                sentence_column.append(dataframe['sentence'][i])\n\n    # end of iteration on all sentences\n    output_df = pd.DataFrame({'sentence':sentence_column, 'dse':dse_column, 'target':target_column, 'agent':agent_column})\n    return output_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:39.960159Z","iopub.execute_input":"2025-02-27T16:22:39.960451Z","iopub.status.idle":"2025-02-27T16:22:39.970402Z","shell.execute_reply.started":"2025-02-27T16:22:39.960414Z","shell.execute_reply":"2025-02-27T16:22:39.969595Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def get_files_of_folder(folder_number):\n    folder = f\"/kaggle/input/ds-json-format/json_format_dataset/{folder_number}\"\n    dev_df = get_data(f\"{folder}/aaai19srl.dev{folder_number}.conll.json\")\n    df = get_data(f\"{folder}/aaai19srl.train{folder_number}.conll.json\")\n    test_df = get_data(f\"{folder}/aaai19srl.test{folder_number}.conll.json\")\n    return df, dev_df, test_df\ndf = get_files_of_folder(FOLD_NUMBER)[0]\ndev_df = get_files_of_folder(FOLD_NUMBER)[1]\ntest_df = get_files_of_folder(FOLD_NUMBER)[2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:39.971254Z","iopub.execute_input":"2025-02-27T16:22:39.971563Z","iopub.status.idle":"2025-02-27T16:22:40.184852Z","shell.execute_reply.started":"2025-02-27T16:22:39.971533Z","shell.execute_reply":"2025-02-27T16:22:40.184148Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# df = get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\")\n\ndf = organize_data(df)\ndev_df = organize_data(dev_df)\ntest_df = organize_data(test_df)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:40.187698Z","iopub.execute_input":"2025-02-27T16:22:40.187944Z","iopub.status.idle":"2025-02-27T16:22:40.317220Z","shell.execute_reply.started":"2025-02-27T16:22:40.187924Z","shell.execute_reply":"2025-02-27T16:22:40.316214Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                               sentence  \\\n0     The Kimberley Provincial Hospital said it woul...   \n1     Saeed said indications were that those tests w...   \n2     He said it was his opinion that the patient --...   \n3     The woman was admitted to the hospital on Satu...   \n4     Private organizations are also being encourage...   \n...                                                 ...   \n3662  A committee of outside directors for the Garde...   \n3663  The unit said it can provide no assurance a tr...   \n3664  Benjamin Franklin Federal Savings & Loan Assoc...   \n3665  thrift said the restructuring should help it m...   \n3666  Details of the restructuring wo n't be made fi...   \n\n                             dse  \\\n0           would probably know|   \n1                          said|   \n2                   his opinion|   \n3                   complaining|   \n4     are also being encouraged|   \n...                          ...   \n3662                      asked|   \n3663   can provide no assurance|   \n3664                      plans|   \n3665                       said|   \n3666                    approve|   \n\n                                             target  \\\n0     whether one of its patients had Congo Fever |   \n1                                     those tests |   \n2                          the patient -- a woman |   \n3                              severe joint pains |   \n4                           help fight sandstorms |   \n...                                             ...   \n3662                                              |   \n3663                     a transaction will occur |   \n3664                                              |   \n3665                            the restructuring |   \n3666                                              |   \n\n                                   agent  \n0     The Kimberley Provincial Hospital|  \n1                                 Saeed|  \n2                                    He|  \n3                             The woman|  \n4                                      |  \n...                                  ...  \n3662                         the parent|  \n3663                           The unit|  \n3664                                 it|  \n3665                                   |  \n3666                         regulators|  \n\n[3667 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>dse</th>\n      <th>target</th>\n      <th>agent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Kimberley Provincial Hospital said it woul...</td>\n      <td>would probably know|</td>\n      <td>whether one of its patients had Congo Fever |</td>\n      <td>The Kimberley Provincial Hospital|</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saeed said indications were that those tests w...</td>\n      <td>said|</td>\n      <td>those tests |</td>\n      <td>Saeed|</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>He said it was his opinion that the patient --...</td>\n      <td>his opinion|</td>\n      <td>the patient -- a woman |</td>\n      <td>He|</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The woman was admitted to the hospital on Satu...</td>\n      <td>complaining|</td>\n      <td>severe joint pains |</td>\n      <td>The woman|</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Private organizations are also being encourage...</td>\n      <td>are also being encouraged|</td>\n      <td>help fight sandstorms |</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3662</th>\n      <td>A committee of outside directors for the Garde...</td>\n      <td>asked|</td>\n      <td>|</td>\n      <td>the parent|</td>\n    </tr>\n    <tr>\n      <th>3663</th>\n      <td>The unit said it can provide no assurance a tr...</td>\n      <td>can provide no assurance|</td>\n      <td>a transaction will occur |</td>\n      <td>The unit|</td>\n    </tr>\n    <tr>\n      <th>3664</th>\n      <td>Benjamin Franklin Federal Savings &amp; Loan Assoc...</td>\n      <td>plans|</td>\n      <td>|</td>\n      <td>it|</td>\n    </tr>\n    <tr>\n      <th>3665</th>\n      <td>thrift said the restructuring should help it m...</td>\n      <td>said|</td>\n      <td>the restructuring |</td>\n      <td>|</td>\n    </tr>\n    <tr>\n      <th>3666</th>\n      <td>Details of the restructuring wo n't be made fi...</td>\n      <td>approve|</td>\n      <td>|</td>\n      <td>regulators|</td>\n    </tr>\n  </tbody>\n</table>\n<p>3667 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def create_prompt(input_df):\n    target_prompt, agent_prompt, target, agent, sentence, dse = [], [], [], [], [], []\n    for i in range(len(input_df)):\n        target_prompt.append(f\"sentence is: {input_df['sentence'][i]} this is verb: {input_df['dse'][i]}. find target for DSE in the sentence?\")\n        agent_prompt.append(f\"sentence is: {input_df['sentence'][i]} this is verb: {input_df['dse'][i]}. find agent for DSE in the sentence?\")\n        target.append(input_df['target'][i])\n        agent.append(input_df['agent'][i])\n        sentence.append(input_df['sentence'][i])\n        dse.append(input_df['dse'][i])\n    output_df = pd.DataFrame({'sentence':sentence, 'dse':dse, 'target_prompt':target_prompt, 'target':target, 'agent_prompt':agent_prompt, 'agent':agent})\n    return output_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:40.318647Z","iopub.execute_input":"2025-02-27T16:22:40.319069Z","iopub.status.idle":"2025-02-27T16:22:40.325118Z","shell.execute_reply.started":"2025-02-27T16:22:40.319037Z","shell.execute_reply":"2025-02-27T16:22:40.324323Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"dev_df = create_prompt(dev_df).reset_index(drop=True)\ntrain_df = create_prompt(df).reset_index(drop=True)\ntest_df = create_prompt(test_df).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:40.326105Z","iopub.execute_input":"2025-02-27T16:22:40.326434Z","iopub.status.idle":"2025-02-27T16:22:40.574668Z","shell.execute_reply.started":"2025-02-27T16:22:40.326404Z","shell.execute_reply":"2025-02-27T16:22:40.574010Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Create a data loader for TRAIN dataframe \ntrain_dataset = CustomDataset(train_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntrain_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n\n# Create a data loader for EVALUATION dataframe\nval_dataset = CustomDataset(dev_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\nval_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n\n# Create a data loader for TEST dataframe\ntest_dataset = CustomDataset(test_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\ntest_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:40.575501Z","iopub.execute_input":"2025-02-27T16:22:40.575760Z","iopub.status.idle":"2025-02-27T16:22:40.580529Z","shell.execute_reply.started":"2025-02-27T16:22:40.575739Z","shell.execute_reply":"2025-02-27T16:22:40.579780Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_data(train_data_loader, val_data_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T16:22:40.581405Z","iopub.execute_input":"2025-02-27T16:22:40.581751Z","execution_failed":"2025-02-27T16:44:46.810Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"name":"stdout","text":"matched: 630, predicted_len: 1488, actual_len: 1514\nmatched: 1115, predicted_len: 1586, actual_len: 1580\nloss: 0.9222564830862242, f1 for target:0.4197201865423052, f1 for agent:0.704358812381554 \n end of epoch0. \n\nmatched: 544, predicted_len: 1488, actual_len: 1198\nmatched: 971, predicted_len: 1586, actual_len: 1325\nloss: 0.34791605200233133, f1 for target:0.4050632911392405, f1 for agent:0.6671246994160083 \n end of epoch1. \n\nmatched: 618, predicted_len: 1488, actual_len: 1388\nmatched: 996, predicted_len: 1586, actual_len: 1412\nloss: 0.21708591520015535, f1 for target:0.4297635605006954, f1 for agent:0.6644429619746497 \n end of epoch2. \n\nmatched: 615, predicted_len: 1488, actual_len: 1343\nmatched: 942, predicted_len: 1586, actual_len: 1359\nloss: 0.1453816721151615, f1 for target:0.43447545037089363, f1 for agent:0.6397283531409167 \n end of epoch3. \n\nmatched: 636, predicted_len: 1488, actual_len: 1412\nmatched: 994, predicted_len: 1586, actual_len: 1471\nloss: 0.10748861049269808, f1 for target:0.4386206896551724, f1 for agent:0.6503107621851488 \n end of epoch4. \n\nmatched: 626, predicted_len: 1488, actual_len: 1371\nmatched: 1001, predicted_len: 1586, actual_len: 1407\nloss: 0.08947028380272717, f1 for target:0.43791535501923745, f1 for agent:0.668894086201136 \n end of epoch5. \n\nmatched: 659, predicted_len: 1488, actual_len: 1548\nmatched: 1039, predicted_len: 1586, actual_len: 1491\nloss: 0.07624005516669874, f1 for target:0.43412384716732544, f1 for agent:0.6753331166720833 \n end of epoch6. \n\nmatched: 613, predicted_len: 1488, actual_len: 1381\nmatched: 997, predicted_len: 1586, actual_len: 1420\nloss: 0.0699677573966569, f1 for target:0.42732659463227607, f1 for agent:0.6633399866932801 \n end of epoch7. \n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot F1 scores for target and agent\nepochs = range(0, EPOCH)\n\nplt.figure(figsize=(10, 6))\nplt.plot(epochs, f1_scores_target, label='F1 Target', marker='o')\nplt.plot(epochs, f1_scores_agent, label='F1 Agent', marker='o')\n\nplt.xlabel('Epochs')\nplt.ylabel('F1 Score')\nplt.title('F1 Scores for Target and Agent over Epochs')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T16:44:46.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_accuracy = evaluate_model(model, test_data_loader, 'target')\nagent_accuracy = evaluate_model(model, test_data_loader, 'agent')\nprint(f'f1 Agent: {agent_accuracy}. f1 Target: {target_accuracy}\\n\\n----------------------')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T16:44:46.810Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"================ test =============== valdiation ============ score values\n\n\n0. fold 0:\n* * Agent : 0.7620064034151548 - 0.6803995006242197\n* * Target: 0.4183908045977011 - 0.46626180836707154\n\n1.  fold 1:\n* * Agent : 0.6957424714434061 - 0.6730578512396694\n* * Target: 0.4331004836109618 - 0.446286701208981\n\n2. fold 2:\n* * Agent : 0.7141242937853107 - 0.7063122923588041\n* * Target: 0.45895745955662076- 0.45473537604456826\n\n\n3. fold 3:\n* * Agent : \n* * Target:\n\n4. fold 4:\n* * Agent :\n* * Target:\n","metadata":{}}]}