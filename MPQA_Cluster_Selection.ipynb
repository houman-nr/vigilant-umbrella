{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6950004,
          "sourceType": "datasetVersion",
          "datasetId": 3991553
        },
        {
          "sourceId": 10302108,
          "sourceType": "datasetVersion",
          "datasetId": 5836801
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2078.052058,
      "end_time": "2024-09-26T12:00:40.153852",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-09-26T11:26:02.101794",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/houman-nr/vigilant-umbrella/blob/main/MPQA_Cluster_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install torch"
      ],
      "metadata": {
        "papermill": {
          "duration": 29.189487,
          "end_time": "2024-09-26T11:26:35.267247",
          "exception": false,
          "start_time": "2024-09-26T11:26:06.077760",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:03.947911Z",
          "iopub.execute_input": "2025-01-08T15:01:03.948235Z",
          "iopub.status.idle": "2025-01-08T15:01:12.411084Z",
          "shell.execute_reply.started": "2025-01-08T15:01:03.948206Z",
          "shell.execute_reply": "2025-01-08T15:01:12.409985Z"
        },
        "id": "6nd5F0Zhm0wM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6451167a-eb72-45ec-a807-6f6c95fc0e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing libraries"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014528,
          "end_time": "2024-09-26T11:26:35.296420",
          "exception": false,
          "start_time": "2024-09-26T11:26:35.281892",
          "status": "completed"
        },
        "tags": [],
        "id": "frzyoRxAm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import json\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from itertools import zip_longest\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "papermill": {
          "duration": 12.728315,
          "end_time": "2024-09-26T11:26:48.042165",
          "exception": false,
          "start_time": "2024-09-26T11:26:35.313850",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:12.412334Z",
          "iopub.execute_input": "2025-01-08T15:01:12.412685Z",
          "iopub.status.idle": "2025-01-08T15:01:16.912207Z",
          "shell.execute_reply.started": "2025-01-08T15:01:12.412661Z",
          "shell.execute_reply": "2025-01-08T15:01:16.911275Z"
        },
        "id": "-wXxZaFVm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('huggingface.co')"
      ],
      "metadata": {
        "id": "6emfaS6HAG9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "d0fef0bc-985f-4042-912e-582432ef69c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret huggingface.co does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-2022970520.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'huggingface.co'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret huggingface.co does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### defining general variables"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.011678,
          "end_time": "2024-09-26T11:26:48.066273",
          "exception": false,
          "start_time": "2024-09-26T11:26:48.054595",
          "status": "completed"
        },
        "tags": [],
        "id": "BbNdoNdDm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining global valriables throughout the whole notebook\n",
        "EPOCH = 32\n",
        "BATCH_SIZE = 64\n",
        "MAX_INPUT_LENGTH = 65\n",
        "MAX_LABEL_LENGTH = 8\n",
        "MODEL_LINK = \"google/flan-t5-small\"\n",
        "FOLD_NUMBER = 0\n",
        "SEED = 0\n",
        "def set_seed():\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed()\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_LINK, legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained(MODEL_LINK).to('cuda')\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.019504,
          "end_time": "2024-09-26T11:26:48.097053",
          "exception": false,
          "start_time": "2024-09-26T11:26:48.077549",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:16.913527Z",
          "iopub.execute_input": "2025-01-08T15:01:16.913955Z",
          "iopub.status.idle": "2025-01-08T15:01:16.917736Z",
          "shell.execute_reply.started": "2025-01-08T15:01:16.913932Z",
          "shell.execute_reply": "2025-01-08T15:01:16.916866Z"
        },
        "id": "Z5vHZRtBm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" links to datasets:\n",
        "for example srl dataset should look like this:\n",
        "srl_data_link = '/kaggle/input/srl-w-cluster-number103k/SRL_Dataset_With_60_Clusters-Similarity.csv'\n",
        "for example for fold_number 0 link for the train should look something like this:\n",
        "df_data_link = organize_data(get_data(\"/kaggle/input/ds-json-format/json_format_dataset/0/aaai19srl.train0.conll.json\"))\n",
        "\"\"\"\n",
        "srl_data_link = \"/content/drive/MyDrive/SRL_data/SRL_Dataset_With_60_Clusters-Similarity.csv\"\n",
        "df_data_link = \"/content/drive/MyDrive/SRL_data/MPQA_dataset/3/aaai19srl.train3.conll.json\"\n",
        "dev_df_data_link = \"/content/drive/MyDrive/SRL_data/MPQA_dataset/3/aaai19srl.dev3.conll.json\"\n",
        "test_df_data_link = \"/content/drive/MyDrive/SRL_data/MPQA_dataset/3/aaai19srl.test3.conll.json\""
      ],
      "metadata": {
        "id": "w1YyHxg68RRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### functions created for reading(get_data) and organize the files (organize_data)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012779,
          "end_time": "2024-09-26T11:26:56.808902",
          "exception": false,
          "start_time": "2024-09-26T11:26:56.796123",
          "status": "completed"
        },
        "tags": [],
        "id": "9UKEsXPnm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a funciton to read data off of a database link is here to help getting and organizing data into dataframes\n",
        "def get_data(address):\n",
        "    lines = []\n",
        "    with open(address) as file:\n",
        "        for line in file:\n",
        "            x = json.loads(line)\n",
        "            lines.append(x)\n",
        "    sentences, orl, sep_sentences = [], [], []\n",
        "    for i in range(len(lines)):\n",
        "        sep_sentences.append(lines[i]['sentences'])\n",
        "        sentences.append(' '.join(lines[i]['sentences']))\n",
        "        orl.append(lines[i]['orl'])\n",
        "    dataframe = pd.DataFrame({'sentence': sentences, 'orl': orl, 'sep_sent': sep_sentences})\n",
        "    return dataframe\n",
        "\n",
        "# this function is to make a list of the said attribute for later iterations\n",
        "def list_of(attributes, requested_atr):\n",
        "    requested_list = []\n",
        "    for sublist in attributes:\n",
        "        if sublist[-1] == requested_atr:\n",
        "            requested_list.append(sublist)\n",
        "    return requested_list\n",
        "\n",
        "# this function was made to find target(s)/agent(s) of a dse according to list of attributes\n",
        "def organize_data(dataframe):\n",
        "\n",
        "    target_column, agent_column, sentence_column, dse_column = [], [], [], []\n",
        "\n",
        "    for i in range(len(dataframe)):\n",
        "\n",
        "        attributes = dataframe['orl'][i]\n",
        "        sentence   = dataframe['sep_sent'][i]\n",
        "        target_list= list_of(attributes, 'TARGET')\n",
        "        agent_list = list_of(attributes, 'AGENT')\n",
        "        AGENT, DSE, TARGET = '', '', ''\n",
        "\n",
        "\n",
        "        for sublist in attributes:\n",
        "            if sublist[-1] == 'DSE':\n",
        "                dse_start = int(sublist[0])\n",
        "                dse_end = int(sublist[1] + 1)\n",
        "                DSE += ' '.join(sentence[dse_start:dse_end]) + '|'\n",
        "\n",
        "\n",
        "                # looking for the targets and agents of this dse that we have found\n",
        "                for sub_sublist in target_list:\n",
        "                    if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n",
        "                        target_start = int(sub_sublist[2])\n",
        "                        target_end = int(sub_sublist[3] + 1)\n",
        "                        TARGET += ' '.join(sentence[target_start:target_end]) + ' |'\n",
        "                if not TARGET:\n",
        "                    TARGET += ' |'\n",
        "\n",
        "                for sub_sublist in agent_list:\n",
        "                    if sub_sublist[0] == dse_start and int(sub_sublist[1] + 1) == dse_end:\n",
        "                        agent_start = int(sub_sublist[2])\n",
        "                        agent_end = int(sub_sublist[3] + 1)\n",
        "                        AGENT += ' '.join(sentence[agent_start:agent_end]) + '|'\n",
        "                if not AGENT:\n",
        "                    AGENT += ' |'\n",
        "                # for every iteration of loop over attributes, if a dse is found, then we need to transfer it to new line of a dataframe\n",
        "                # for each one of the dse(s) i have to add them into a new array so then they can create the correct dataframe\n",
        "                target_column.append(TARGET)\n",
        "                agent_column.append(AGENT)\n",
        "                dse_column.append(DSE)\n",
        "                sentence_column.append(dataframe['sentence'][i])\n",
        "\n",
        "    # end of iteration on all sentences\n",
        "    output_df = pd.DataFrame({'sentence':sentence_column, 'dse':dse_column, 'target':target_column, 'agent':agent_column})\n",
        "    return output_df"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.03125,
          "end_time": "2024-09-26T11:26:56.853271",
          "exception": false,
          "start_time": "2024-09-26T11:26:56.822021",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:20.735540Z",
          "iopub.execute_input": "2025-01-08T15:01:20.735930Z",
          "iopub.status.idle": "2025-01-08T15:01:20.745976Z",
          "shell.execute_reply.started": "2025-01-08T15:01:20.735906Z",
          "shell.execute_reply": "2025-01-08T15:01:20.745190Z"
        },
        "id": "-9SC6R1dm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a function to call for different links of folders with exact process to extract and organize data"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012314,
          "end_time": "2024-09-26T11:26:56.878259",
          "exception": false,
          "start_time": "2024-09-26T11:26:56.865945",
          "status": "completed"
        },
        "tags": [],
        "id": "SL8OI-r3m0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "links to respective data with heavy notice on the fold number should be given to the get_data()\n",
        "for example for fold_number 0 link for the train should look something like this:\n",
        "df = organize_data(get_data(dev_df_data_link))\n",
        "\"\"\"\n",
        "dev_df = organize_data(get_data(dev_df_data_link))\n",
        "df = organize_data(get_data(df_data_link))\n",
        "test_df = organize_data(get_data(test_df_data_link))"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.297844,
          "end_time": "2024-09-26T11:26:57.189268",
          "exception": false,
          "start_time": "2024-09-26T11:26:56.891424",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:20.746687Z",
          "iopub.execute_input": "2025-01-08T15:01:20.746876Z",
          "iopub.status.idle": "2025-01-08T15:01:20.935613Z",
          "shell.execute_reply.started": "2025-01-08T15:01:20.746860Z",
          "shell.execute_reply": "2025-01-08T15:01:20.934962Z"
        },
        "id": "jI6rkrMjm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### getting training/validation/test data into data frames and dividing each of {agent, target, dse} elements"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.012592,
          "end_time": "2024-09-26T11:26:57.214978",
          "exception": false,
          "start_time": "2024-09-26T11:26:57.202386",
          "status": "completed"
        },
        "tags": [],
        "id": "MLdCIJ80m0wM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting evaluation data into df and dividing each of {agent, target, dse} elements"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014221,
          "end_time": "2024-09-26T11:27:00.021124",
          "exception": false,
          "start_time": "2024-09-26T11:27:00.006903",
          "status": "completed"
        },
        "tags": [],
        "id": "GPy8r0MUm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function which will write prompt for the model according to the sentence and the items in it\n",
        "def create_prompt(input_df):\n",
        "    target_prompt, agent_prompt, target, agent, sentence, dse = [], [], [], [], [], []\n",
        "    for i in range(len(input_df)):\n",
        "        target_prompt.append(f\"sentence is: {input_df['sentence'][i]} this is verb: {input_df['dse'][i]}. find target for DSE in the sentence?\")\n",
        "        agent_prompt.append(f\"sentence is: {input_df['sentence'][i]} this is verb: {input_df['dse'][i]}. find agent for DSE in the sentence?\")\n",
        "        target.append(input_df['target'][i])\n",
        "        agent.append(input_df['agent'][i])\n",
        "        sentence.append(input_df['sentence'][i])\n",
        "        dse.append(input_df['dse'][i])\n",
        "    output_df = pd.DataFrame({'sentence':sentence, 'dse':dse, 'target_prompt':target_prompt, 'target':target, 'agent_prompt':agent_prompt, 'agent':agent})\n",
        "    return output_df"
      ],
      "metadata": {
        "papermill": {
          "duration": 3.176629,
          "end_time": "2024-09-26T11:27:03.249717",
          "exception": false,
          "start_time": "2024-09-26T11:27:00.073088",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.082259Z",
          "iopub.execute_input": "2025-01-08T15:01:21.082579Z",
          "iopub.status.idle": "2025-01-08T15:01:21.101253Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.082557Z",
          "shell.execute_reply": "2025-01-08T15:01:21.100529Z"
        },
        "id": "rdapHTIfm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the sentence and dse into a prompt according to information in that row\n",
        "#### change will be applied on all three data frames {train, test, validation}"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.017877,
          "end_time": "2024-09-26T11:27:03.282229",
          "exception": false,
          "start_time": "2024-09-26T11:27:03.264352",
          "status": "completed"
        },
        "tags": [],
        "id": "NmWXRRHSm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df = create_prompt(dev_df).reset_index(drop=True)\n",
        "train_df = create_prompt(df).reset_index(drop=True)\n",
        "test_df = create_prompt(test_df).reset_index(drop=True)"
      ],
      "metadata": {
        "papermill": {
          "duration": 5.143976,
          "end_time": "2024-09-26T11:27:08.441865",
          "exception": false,
          "start_time": "2024-09-26T11:27:03.297889",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.102144Z",
          "iopub.execute_input": "2025-01-08T15:01:21.102439Z",
          "iopub.status.idle": "2025-01-08T15:01:21.340524Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.102409Z",
          "shell.execute_reply": "2025-01-08T15:01:21.339867Z"
        },
        "id": "SxNh774bm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length4text, max_length4label):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length4text = max_length4text\n",
        "        self.max_length4label = max_length4label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        agent_prompt = self.data['agent_prompt'][idx]\n",
        "        target_prompt = self.data['target_prompt'][idx]\n",
        "        agent = self.data['agent'][idx]\n",
        "        target = self.data['target'][idx]\n",
        "        # tokenizing agent prompt\n",
        "        agent_prompt_encoding = self.tokenizer(agent_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n",
        "        # tokenizing target prompt\n",
        "        target_prompt_encoding = self.tokenizer(target_prompt, truncation=True, padding='max_length', max_length=self.max_length4text, return_tensors='pt').to(\"cuda\")\n",
        "        # tokenizing agent\n",
        "        agent_encoding = self.tokenizer(agent, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n",
        "        # tokenizing target\n",
        "        target_encoding = self.tokenizer(target, truncation=True, padding='max_length', max_length=self.max_length4label, return_tensors='pt').to(\"cuda\")\n",
        "        return {\n",
        "            # agent prompt\n",
        "            'agent_input_id': agent_prompt_encoding['input_ids'].squeeze(),\n",
        "            'agent_attention_mask': agent_prompt_encoding['attention_mask'].squeeze(),\n",
        "            # target prompt\n",
        "            'target_input_id': target_prompt_encoding['input_ids'].squeeze(),\n",
        "            'target_attention_mask': target_prompt_encoding['attention_mask'].squeeze(),\n",
        "            #agent\n",
        "            'agent_id': agent_encoding['input_ids'].squeeze(),\n",
        "            'agent_mask': agent_encoding['attention_mask'].squeeze(),\n",
        "            #target\n",
        "            'target_id': target_encoding['input_ids'].squeeze(),\n",
        "            'target_mask': target_encoding['attention_mask'].squeeze()\n",
        "        }"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.029669,
          "end_time": "2024-09-26T11:27:08.487210",
          "exception": false,
          "start_time": "2024-09-26T11:27:08.457541",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.341322Z",
          "iopub.execute_input": "2025-01-08T15:01:21.341594Z",
          "iopub.status.idle": "2025-01-08T15:01:21.348821Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.341564Z",
          "shell.execute_reply": "2025-01-08T15:01:21.347897Z"
        },
        "id": "kRJgX46nm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.828199,
          "end_time": "2024-09-26T11:27:09.329609",
          "exception": false,
          "start_time": "2024-09-26T11:27:08.501410",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.349604Z",
          "iopub.execute_input": "2025-01-08T15:01:21.349879Z",
          "iopub.status.idle": "2025-01-08T15:01:21.827836Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.349846Z",
          "shell.execute_reply": "2025-01-08T15:01:21.826962Z"
        },
        "id": "4aREPdaGm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_calculator(split_pred_list, split_actual_list):\n",
        "    matched, percision, recall, f1 = 0, 0, 0, 0\n",
        "    predicted_len, actual_len      = 0, 0\n",
        "\n",
        "    for actual_sublist, prediction_sublist in zip(split_pred_list, split_actual_list):\n",
        "        predicted_len += len(prediction_sublist)\n",
        "        for i in actual_sublist:\n",
        "            actual_len += 1\n",
        "            if i in prediction_sublist:\n",
        "                matched += 1\n",
        "\n",
        "    print(f\"matched: {matched}, predicted_len: {predicted_len}, actual_len: {actual_len}\")\n",
        "    try:\n",
        "        precision = matched / predicted_len\n",
        "        recall = matched / actual_len\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    except ZeroDivisionError:\n",
        "        f1 = 0\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.0255,
          "end_time": "2024-09-26T11:27:09.370039",
          "exception": false,
          "start_time": "2024-09-26T11:27:09.344539",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.828711Z",
          "iopub.execute_input": "2025-01-08T15:01:21.829099Z",
          "iopub.status.idle": "2025-01-08T15:01:21.833935Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.829078Z",
          "shell.execute_reply": "2025-01-08T15:01:21.833162Z"
        },
        "id": "NFcIv8Y-m0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_data(text_list):\n",
        "    list_of_items_in_text = []\n",
        "    for single_list in text_list:\n",
        "        for i in single_list.split('|'):\n",
        "            i = i.lower().replace(\" \", \"\")  # Convert to lowercase and remove extra whitespace\n",
        "            if i:  # Check if `i` is not empty after stripping\n",
        "                list_of_items_in_text.append(i)\n",
        "    return list_of_items_in_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.834761Z",
          "iopub.execute_input": "2025-01-08T15:01:21.835031Z",
          "iopub.status.idle": "2025-01-08T15:01:21.852778Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.834997Z",
          "shell.execute_reply": "2025-01-08T15:01:21.852015Z"
        },
        "id": "K94xVL4zm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, prompt_type):\n",
        "    if prompt_type == 'target':\n",
        "        id_type = 'target_input_id'\n",
        "        attention_type = 'target_attention_mask'\n",
        "        output_type = 'target_id'\n",
        "    elif prompt_type == 'agent':\n",
        "        id_type = 'agent_input_id'\n",
        "        attention_type = 'agent_attention_mask'\n",
        "        output_type = 'agent_id'\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        actual_list, prediction_list = [], []\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "\n",
        "            # Forward pass\n",
        "            ids = batch[id_type]\n",
        "            mask = batch[attention_type]\n",
        "            output_id = batch[output_type]\n",
        "\n",
        "            actuals = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in output_id]\n",
        "\n",
        "            generated_output = model.generate(\n",
        "              input_ids = ids,\n",
        "              attention_mask = mask,\n",
        "              max_length=64,\n",
        "              )\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_output]\n",
        "\n",
        "            actual_list.append(clear_data(actuals))\n",
        "            prediction_list.append(clear_data(preds))\n",
        "\n",
        "    return f1_calculator(prediction_list, actual_list)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.030366,
          "end_time": "2024-09-26T11:27:09.415309",
          "exception": false,
          "start_time": "2024-09-26T11:27:09.384943",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.853604Z",
          "iopub.execute_input": "2025-01-08T15:01:21.853874Z",
          "iopub.status.idle": "2025-01-08T15:01:21.866607Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.853846Z",
          "shell.execute_reply": "2025-01-08T15:01:21.865982Z"
        },
        "id": "BRWVsSGbm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores_target, f1_scores_agent = [], []\n",
        "\n",
        "def train_data(data_loader, v_data_loader):\n",
        "    data_list = []\n",
        "    model.train()\n",
        "    for epoch in range(EPOCH):\n",
        "        losses = []\n",
        "        for batch in data_loader:\n",
        "\n",
        "            agent_input = batch['agent_input_id']\n",
        "            agent_attention_mask = batch['agent_attention_mask']\n",
        "\n",
        "            target_input = batch['target_input_id']\n",
        "            target_attention_mask = batch['target_attention_mask']\n",
        "\n",
        "            agent_id = batch['agent_id']\n",
        "            agent_mask = batch['agent_mask']\n",
        "\n",
        "            target_id = batch['target_id']\n",
        "            target_mask = batch['target_mask']\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            agent_output = model(agent_input, attention_mask=agent_attention_mask, labels=agent_id)\n",
        "            target_output = model(target_input, attention_mask=target_attention_mask, labels=target_id)\n",
        "\n",
        "            agent_loss = agent_output.loss\n",
        "            target_loss = target_output.loss\n",
        "            losses.append(agent_loss.item())\n",
        "            losses.append(target_loss.item())\n",
        "\n",
        "            agent_loss.backward()\n",
        "            target_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        f1_4_target = evaluate_model(model, v_data_loader, 'target')\n",
        "        f1_4_agent = evaluate_model(model, v_data_loader, 'agent')\n",
        "\n",
        "        f1_scores_target.append(f1_4_target)\n",
        "        f1_scores_agent.append(f1_4_agent)\n",
        "\n",
        "        # report the results of training function.\n",
        "        print(f'loss: {np.mean(losses)}, f1 for target:{f1_4_target}, f1 for agent:{f1_4_agent} \\n end of epoch{epoch}. \\n')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.027986,
          "end_time": "2024-09-26T11:27:09.457947",
          "exception": false,
          "start_time": "2024-09-26T11:27:09.429961",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.867276Z",
          "iopub.execute_input": "2025-01-08T15:01:21.867495Z",
          "iopub.status.idle": "2025-01-08T15:01:21.884923Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.867465Z",
          "shell.execute_reply": "2025-01-08T15:01:21.884252Z"
        },
        "id": "6c7u99DUm0wM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# By this box, mpqa/orl data is ready to be combined with different forms of clustering being applied on the rest of the data"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.014514,
          "end_time": "2024-09-26T11:27:09.487230",
          "exception": false,
          "start_time": "2024-09-26T11:27:09.472716",
          "status": "completed"
        },
        "tags": [],
        "id": "zYyfX6CGm0wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "srl = pd.read_csv(srl_data_link)\n",
        "agents, targets, verbs, sentences, cluster_number, cosin_value = [], [], [], [], [], []\n",
        "for i in range(len(srl)):\n",
        "\n",
        "    #single line of data is selected from df\n",
        "    line = srl.iloc[i]\n",
        "\n",
        "    #check for both ARGS,\n",
        "    #if both are empty skips that line.\n",
        "    #if either one of the args is filled-\n",
        "    #-process continues.\n",
        "    if line['ARG0'] or line['ARG1']:\n",
        "        if line['ARG0']:\n",
        "            agents.append(line['ARG0'])\n",
        "        else:\n",
        "            agents.append(\"\")\n",
        "        if line['ARG1']:\n",
        "            targets.append(line['ARG1'])\n",
        "        else:\n",
        "            targets.append(\"\")\n",
        "        sentences.append(line['SENTENCE'])\n",
        "        verbs.append(line['PREDICATES'])\n",
        "        cluster_number.append(line['Cluster_Number'])\n",
        "        cosin_value.append(line['Similarity'])\n",
        "\n",
        "srl_df = pd.DataFrame({'sentences': sentences,\n",
        "                       'verbs': verbs,\n",
        "                       'agents': agents,\n",
        "                       'targets': targets,\n",
        "                       'cluster_no': cluster_number,\n",
        "                       'cosin_value': cosin_value},\n",
        "                      dtype='object').fillna('')\n",
        "srl_df"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.156441,
          "end_time": "2024-09-26T11:27:10.689172",
          "exception": false,
          "start_time": "2024-09-26T11:27:09.532731",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:21.885686Z",
          "iopub.execute_input": "2025-01-08T15:01:21.885875Z",
          "iopub.status.idle": "2025-01-08T15:01:28.270323Z",
          "shell.execute_reply.started": "2025-01-08T15:01:21.885858Z",
          "shell.execute_reply": "2025-01-08T15:01:28.269533Z"
        },
        "id": "d4gNRildm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompts, agents, target_prompts, targets, cluster_no, cosin_value = [], [], [], [], [], []\n",
        "for i in range(len(srl_df)):\n",
        "    line = srl_df.iloc[i]\n",
        "    agent_prompts.append(f\"sentence is: {line['sentences']} this is verb: {line['verbs']} find agent for this veerb in the sentence\")\n",
        "    agents.append(line['agents'])\n",
        "    target_prompts.append(f\"sentence is: {line['sentences']} this is verb: {line['verbs']} find target for this verb in the sentence\")\n",
        "    targets.append(line['targets'])\n",
        "    cluster_no.append(line['cluster_no'])\n",
        "    cosin_value.append(line['cosin_value'])\n",
        "srl_df = []\n",
        "srl_df = pd.DataFrame({'agent_prompt': agent_prompts,\n",
        "                       'agent': agents,\n",
        "                       'target_prompt': target_prompts,\n",
        "                       'target': targets,\n",
        "                       'cluster_no': cluster_number,\n",
        "                       'cosin_value': cosin_value})\n",
        "srl_df"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.730236,
          "end_time": "2024-09-26T11:27:11.435423",
          "exception": false,
          "start_time": "2024-09-26T11:27:10.705187",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:28.271187Z",
          "iopub.execute_input": "2025-01-08T15:01:28.271508Z",
          "iopub.status.idle": "2025-01-08T15:01:33.873852Z",
          "shell.execute_reply.started": "2025-01-08T15:01:28.271480Z",
          "shell.execute_reply": "2025-01-08T15:01:33.873094Z"
        },
        "id": "k3ht_xdIm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### randomly selecting number of this dataframe to be fed into the model\n",
        "\n",
        "##### 4000 lines of data is the limit of notebook with GPU T4*2 memory limit\n",
        "##### 60 clusters to chose from, Results in almost 66.6... from each cluster"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.015757,
          "end_time": "2024-09-26T11:27:11.467508",
          "exception": false,
          "start_time": "2024-09-26T11:27:11.451751",
          "status": "completed"
        },
        "tags": [],
        "id": "uFREv-i0m0wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sample_df(df, num_rows, SEED=None):\n",
        "    # Check if num_rows is larger than the available number of rows in the DataFrame\n",
        "    if num_rows > len(df):\n",
        "        raise ValueError(f\"Requested {num_rows} rows, but the DataFrame only contains {len(df)} rows.\")\n",
        "\n",
        "    # Sample the DataFrame and return the result\n",
        "    sampled_df = df.sample(n=num_rows, random_state=SEED)\n",
        "    return sampled_df\n",
        "\n",
        "def random_sample_from_all_clusters(df, num_rows_per_cluster, cluster_column, SEED=None):\n",
        "    # Check if the cluster_column exists in the DataFrame\n",
        "    if cluster_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{cluster_column}' not found in DataFrame.\")\n",
        "\n",
        "    # Create an empty list to hold the sampled data for each cluster\n",
        "    sampled_dfs = []\n",
        "\n",
        "    # Group the DataFrame by the cluster column\n",
        "    grouped = df.groupby(cluster_column)\n",
        "\n",
        "    # Iterate over each cluster and sample rows\n",
        "    for cluster, group in grouped:\n",
        "        # Check if the group has enough rows to sample\n",
        "        if len(group) < num_rows_per_cluster:\n",
        "            raise ValueError(f\"Cluster '{cluster}' has only {len(group)} rows, but {num_rows_per_cluster} were requested.\")\n",
        "\n",
        "        # Sample the rows from the current cluster\n",
        "        sampled_group = group.sample(n=num_rows_per_cluster, random_state=SEED)\n",
        "        sampled_dfs.append(sampled_group)\n",
        "\n",
        "    # Concatenate the sampled DataFrames for each cluster\n",
        "    sampled_df = pd.concat(sampled_dfs).reset_index(drop=True)\n",
        "\n",
        "    return sampled_df\n",
        "\n",
        "\n",
        "srl_train_nk = random_sample_from_all_clusters(srl_df, 66, 'cluster_no', SEED)\n",
        "srl_train_nk"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.038497,
          "end_time": "2024-09-26T11:27:11.521955",
          "exception": false,
          "start_time": "2024-09-26T11:27:11.483458",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:33.874641Z",
          "iopub.execute_input": "2025-01-08T15:01:33.874897Z",
          "iopub.status.idle": "2025-01-08T15:01:33.954633Z",
          "shell.execute_reply.started": "2025-01-08T15:01:33.874866Z",
          "shell.execute_reply": "2025-01-08T15:01:33.953906Z"
        },
        "id": "CsMg5r1Um0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_and_shuffle(df1, df2, SEED=None):\n",
        "    \"\"\"\n",
        "    Combines two DataFrames with the same columns and shuffles the rows.\n",
        "\n",
        "    Args:\n",
        "        df1 (pd.DataFrame): The first DataFrame.\n",
        "        df2 (pd.DataFrame): The second DataFrame.\n",
        "        seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with rows from both DataFrames shuffled.\n",
        "    \"\"\"\n",
        "    # Combine the two DataFrames using pd.concat\n",
        "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # Shuffle the combined DataFrame\n",
        "    shuffled_df = combined_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "    return shuffled_df\n",
        "orl_srl = combine_and_shuffle(train_df, srl_train_nk, SEED)\n",
        "orl_srl.drop(columns=['cluster_no', 'sentence', 'dse'], inplace=True)\n",
        "orl_srl"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.046525,
          "end_time": "2024-09-26T11:27:11.586317",
          "exception": false,
          "start_time": "2024-09-26T11:27:11.539792",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:33.955436Z",
          "iopub.execute_input": "2025-01-08T15:01:33.955723Z",
          "iopub.status.idle": "2025-01-08T15:01:33.978080Z",
          "shell.execute_reply.started": "2025-01-08T15:01:33.955700Z",
          "shell.execute_reply": "2025-01-08T15:01:33.977361Z"
        },
        "id": "qi2bhJVgm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data loader for TRAIN dataframe\n",
        "train_dataset = CustomDataset(orl_srl, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n",
        "train_data_loader = DataLoader(train_dataset, batch_size= BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Create a data loader for EVALUATION dataframe\n",
        "val_dataset = CustomDataset(dev_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n",
        "val_data_loader = DataLoader(val_dataset, batch_size= BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Create a data loader for TEST dataframe\n",
        "test_dataset = CustomDataset(test_df, tokenizer, max_length4text= MAX_INPUT_LENGTH, max_length4label= MAX_LABEL_LENGTH)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.025499,
          "end_time": "2024-09-26T11:27:11.629151",
          "exception": false,
          "start_time": "2024-09-26T11:27:11.603652",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:33.981552Z",
          "iopub.execute_input": "2025-01-08T15:01:33.981774Z",
          "iopub.status.idle": "2025-01-08T15:01:33.986439Z",
          "shell.execute_reply.started": "2025-01-08T15:01:33.981755Z",
          "shell.execute_reply": "2025-01-08T15:01:33.985641Z"
        },
        "id": "so-7WhXbm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data(train_data_loader, val_data_loader)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1973.261252,
          "end_time": "2024-09-26T12:00:04.906971",
          "exception": false,
          "start_time": "2024-09-26T11:27:11.645719",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:01:33.999899Z",
          "iopub.execute_input": "2025-01-08T15:01:34.000264Z",
          "iopub.status.idle": "2025-01-08T15:53:19.149335Z",
          "shell.execute_reply.started": "2025-01-08T15:01:34.000233Z",
          "shell.execute_reply": "2025-01-08T15:53:19.148558Z"
        },
        "id": "p7MMxRhWm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot F1 scores for target and agent\n",
        "epochs = range(0, EPOCH)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, f1_scores_target, label='F1 Target', marker='o')\n",
        "plt.plot(epochs, f1_scores_agent, label='F1 Agent', marker='o')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('F1 Scores for Target and Agent over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.462293,
          "end_time": "2024-09-26T12:00:05.387802",
          "exception": false,
          "start_time": "2024-09-26T12:00:04.925509",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:53:19.151128Z",
          "iopub.execute_input": "2025-01-08T15:53:19.151362Z",
          "iopub.status.idle": "2025-01-08T15:53:19.493996Z",
          "shell.execute_reply.started": "2025-01-08T15:53:19.151341Z",
          "shell.execute_reply": "2025-01-08T15:53:19.493181Z"
        },
        "id": "LqS62-Xzm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "target_accuracy = evaluate_model(model, val_data_loader, 'target')\n",
        "agent_accuracy = evaluate_model(model, val_data_loader, 'agent')\n",
        "print(f'f1 Agent: {agent_accuracy}. f1 Target: {target_accuracy}\\n\\n----------------------')"
      ],
      "metadata": {
        "papermill": {
          "duration": 31.79925,
          "end_time": "2024-09-26T12:00:37.496787",
          "exception": false,
          "start_time": "2024-09-26T12:00:05.697537",
          "status": "completed"
        },
        "tags": [],
        "_kg_hide-output": true,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T15:53:19.494817Z",
          "iopub.execute_input": "2025-01-08T15:53:19.495084Z",
          "iopub.status.idle": "2025-01-08T15:53:38.181410Z",
          "shell.execute_reply.started": "2025-01-08T15:53:19.495053Z",
          "shell.execute_reply": "2025-01-08T15:53:38.180648Z"
        },
        "id": "jtrEKAEdm0wc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Fold 0: f1 Agent: 0.6761683791846206. f1 Target: 0.454513767863367\n",
        "- Fold 1: f1 Agent: 0.6555851063829787. f1 Target: 0.42896742896742895\n",
        "- Fold 2: f1 Agent: 0.6597537265068049. f1 Target: 0.43398230088495576\n",
        "- Fold 3: f1 Agent: 0.6985055230669265. f1 Target: 0.4430122116689281\n",
        "- Fold 4: f1 Agent: 0.6776207689779824. f1 Target: 0.44245348035837356"
      ],
      "metadata": {
        "id": "80LHuU3Ix5Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Fold0f1Agent = 0.6761683791846206\n",
        "Fold0f1Target = 0.454513767863367\n",
        "Fold1f1Agent = 0.6555851063829787\n",
        "Fold1f1Target = 0.42896742896742895\n",
        "Fold2f1Agent = 0.6597537265068049\n",
        "Fold2f1Target = 0.43398230088495576\n",
        "Fold3f1Agent = 0.6985055230669265\n",
        "Fold3f1Target = 0.4430122116689281\n",
        "Fold4f1Agent = 0.6776207689779824\n",
        "Fold4f1Target = 0.44245348035837356\n",
        "\n",
        "\n",
        "Agent_sum = Fold0f1Agent + Fold1f1Agent + Fold2f1Agent + Fold3f1Agent + Fold4f1Agent\n",
        "Target_sum = Fold0f1Target + Fold1f1Target + Fold2f1Target + Fold3f1Target + Fold4f1Target\n",
        "Agent_mean = Agent_sum / 5\n",
        "Target_mean = Target_sum / 5\n",
        "print(f'Agent_mean: {Agent_mean}, Target_mean: {Target_mean}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4ekwtfndQHZ",
        "outputId": "d3c45bf9-f965-4cad-f107-ba3de4168dc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent_mean: 0.6735267008238626, Target_mean: 0.44058583794861067\n"
          ]
        }
      ]
    }
  ]
}